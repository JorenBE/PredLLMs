nohup: ignoring input
2023-04-06 22:18:08.085441: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-06 22:18:08.147369: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-04-06 22:18:08.149502: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2023-04-06 22:18:08.149513: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-04-06 22:18:08.461068: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-04-06 22:18:08.461108: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-04-06 22:18:08.461114: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
==============================WARNING: DEPRECATED!==============================
WARNING! This version of bitsandbytes is deprecated. Please switch to `pip install bitsandbytes` and the new repo: https://github.com/TimDettmers/bitsandbytes
==============================WARNING: DEPRECATED!==============================
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/200 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 1/200 [00:01<03:47,  1.14s/it]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 2/200 [00:01<03:08,  1.05it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 3/200 [00:02<02:53,  1.13it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 4/200 [00:03<02:46,  1.18it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▎         | 5/200 [00:04<02:42,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 6/200 [00:05<02:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▎         | 7/200 [00:05<02:37,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 8/200 [00:06<02:35,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 9/200 [00:07<02:34,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▌         | 10/200 [00:08<02:32,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 11/200 [00:09<02:31,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 12/200 [00:09<02:30,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▋         | 13/200 [00:10<02:29,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 14/200 [00:11<02:28,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 15/200 [00:12<02:27,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 16/200 [00:13<02:26,  1.26it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 17/200 [00:13<02:25,  1.26it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 18/200 [00:14<02:25,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|▉         | 19/200 [00:15<02:24,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 20/200 [00:16<02:23,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 21/200 [00:17<02:22,  1.26it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 22/200 [00:17<02:21,  1.26it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 23/200 [00:18<02:20,  1.26it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 24/200 [00:19<02:20,  1.26it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▎        | 25/200 [00:20<02:19,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 26/200 [00:21<02:18,  1.26it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▎        | 27/200 [00:21<02:17,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 28/200 [00:22<02:17,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 29/200 [00:23<02:16,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▌        | 30/200 [00:24<02:15,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 31/200 [00:25<02:15,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 32/200 [00:25<02:14,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▋        | 33/200 [00:26<02:13,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 34/200 [00:27<02:13,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 35/200 [00:28<02:12,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 36/200 [00:29<02:11,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 37/200 [00:29<02:10,  1.25it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 38/200 [00:30<02:10,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|█▉        | 39/200 [00:31<02:09,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 40/200 [00:32<02:08,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 41/200 [00:33<02:07,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 42/200 [00:33<02:07,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 43/200 [00:34<02:06,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 44/200 [00:35<02:05,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▎       | 45/200 [00:36<02:05,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 46/200 [00:37<02:04,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▎       | 47/200 [00:37<02:03,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 48/200 [00:38<02:02,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 49/200 [00:39<02:02,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▌       | 50/200 [00:40<02:01,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 51/200 [00:41<02:00,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 52/200 [00:42<01:59,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▋       | 53/200 [00:42<01:58,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 54/200 [00:43<01:58,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 55/200 [00:44<01:57,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 56/200 [00:45<01:56,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 57/200 [00:46<01:55,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 58/200 [00:46<01:54,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|██▉       | 59/200 [00:47<01:54,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 60/200 [00:48<01:53,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 61/200 [00:49<01:52,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 62/200 [00:50<01:51,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 63/200 [00:50<01:51,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 64/200 [00:51<01:50,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▎      | 65/200 [00:52<01:49,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 66/200 [00:53<01:48,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▎      | 67/200 [00:54<01:48,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 68/200 [00:54<01:47,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 69/200 [00:55<01:46,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▌      | 70/200 [00:56<01:45,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 71/200 [00:57<01:44,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 72/200 [00:58<01:44,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▋      | 73/200 [00:59<01:43,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 74/200 [00:59<01:42,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 75/200 [01:00<01:41,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 76/200 [01:01<01:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 77/200 [01:02<01:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 78/200 [01:03<01:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|███▉      | 79/200 [01:03<01:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 80/200 [01:04<01:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 81/200 [01:05<01:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 82/200 [01:06<01:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 83/200 [01:07<01:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 84/200 [01:08<01:35,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▎     | 85/200 [01:08<01:34,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 86/200 [01:09<01:33,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▎     | 87/200 [01:10<01:33,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 88/200 [01:11<01:32,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 89/200 [01:12<01:32,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▌     | 90/200 [01:13<01:31,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 91/200 [01:13<01:30,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 92/200 [01:14<01:30,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▋     | 93/200 [01:15<01:29,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 94/200 [01:16<01:29,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 95/200 [01:17<01:28,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 96/200 [01:18<01:27,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 97/200 [01:18<01:26,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 98/200 [01:19<01:26,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|████▉     | 99/200 [01:20<01:25,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 100/200 [01:21<01:24,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 101/200 [01:22<01:23,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 102/200 [01:23<01:22,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 103/200 [01:24<01:21,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 104/200 [01:24<01:20,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▎    | 105/200 [01:25<01:19,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 106/200 [01:26<01:18,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▎    | 107/200 [01:27<01:17,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 108/200 [01:28<01:16,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▍    | 109/200 [01:28<01:15,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▌    | 110/200 [01:29<01:14,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 111/200 [01:30<01:13,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 112/200 [01:31<01:12,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▋    | 113/200 [01:32<01:11,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 114/200 [01:33<01:10,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▊    | 115/200 [01:33<01:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 116/200 [01:34<01:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 117/200 [01:35<01:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 118/200 [01:36<01:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|█████▉    | 119/200 [01:37<01:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 120/200 [01:38<01:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 121/200 [01:38<01:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 122/200 [01:39<01:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 123/200 [01:40<01:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 124/200 [01:41<01:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▎   | 125/200 [01:42<01:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 126/200 [01:42<01:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▎   | 127/200 [01:43<00:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 128/200 [01:44<00:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 129/200 [01:45<00:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▌   | 130/200 [01:46<00:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 131/200 [01:47<00:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 132/200 [01:47<00:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▋   | 133/200 [01:48<00:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 134/200 [01:49<00:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 135/200 [01:50<00:53,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 136/200 [01:51<00:52,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 137/200 [01:51<00:51,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 138/200 [01:52<00:50,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|██████▉   | 139/200 [01:53<00:49,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 140/200 [01:54<00:48,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 141/200 [01:55<00:48,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 142/200 [01:55<00:47,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 143/200 [01:56<00:46,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 144/200 [01:57<00:45,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▎  | 145/200 [01:58<00:44,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 146/200 [01:59<00:44,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
tensor(8.0992, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.9078, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.3211, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.5540, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.6858, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.0765, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.7382, device='cuda:0', grad_fn=<AddBackward0>)
tensor(9.4936, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.6463, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.0385, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.5417, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.7419, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.9357, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.3556, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.2278, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.3921, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.3725, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.3009, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.6408, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.8069, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.0605, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.6700, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.2599, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.2321, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.3381, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.9723, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.2264, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.0031, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.4210, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.2559, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.1112, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.6582, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.5966, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.3515, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.0205, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.6990, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.5320, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.2910, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.7893, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4715, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.5207, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.7296, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.7716, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.7532, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.6169, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4634, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.5740, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4384, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4042, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.5036, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3589, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4153, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2680, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2081, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0502, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1103, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2609, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.5367, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0645, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1563, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1157, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1230, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2651, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2609, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0809, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1349, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1080, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9411, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0163, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9808, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0901, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9329, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0367, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9527, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0633, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0253, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1059, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9757, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9452, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9883, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8992, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0224, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8361, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9944, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0652, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9487, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9856, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8533, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8897, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0432, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8627, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9234, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7924, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9154, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7931, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8158, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7701, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8235, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8979, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7753, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7512, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9129, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8169, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8857, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7928, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9167, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8282, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7288, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7535, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8627, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7965, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8621, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8976, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1302, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8174, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8367, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8598, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8336, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8002, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7390, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7641, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7198, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8676, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6858, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6886, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7821, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8716, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6965, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7345, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9021, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9056, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8262, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8056, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7465, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8593, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7006, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7511, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7067, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7190, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8710, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7612, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7863, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7219, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8159, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7114, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7888, device='cuda:0', grad_fn=<AddBackward0>)
 74%|███████▎  | 147/200 [02:00<00:43,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 148/200 [02:00<00:42,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 149/200 [02:01<00:41,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▌  | 150/200 [02:02<00:40,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 151/200 [02:03<00:39,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 152/200 [02:04<00:39,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▋  | 153/200 [02:04<00:38,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 154/200 [02:05<00:37,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 155/200 [02:06<00:36,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 156/200 [02:07<00:35,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 157/200 [02:08<00:35,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 158/200 [02:09<00:34,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|███████▉  | 159/200 [02:09<00:33,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 160/200 [02:10<00:32,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 161/200 [02:11<00:31,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 162/200 [02:12<00:31,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 163/200 [02:13<00:30,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 164/200 [02:13<00:29,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▎ | 165/200 [02:14<00:28,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 166/200 [02:15<00:27,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▎ | 167/200 [02:16<00:26,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 168/200 [02:17<00:26,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 169/200 [02:18<00:25,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▌ | 170/200 [02:18<00:24,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 171/200 [02:19<00:23,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 172/200 [02:20<00:22,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▋ | 173/200 [02:21<00:22,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 174/200 [02:22<00:21,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 175/200 [02:22<00:20,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 176/200 [02:23<00:19,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 177/200 [02:24<00:18,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 178/200 [02:25<00:17,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|████████▉ | 179/200 [02:26<00:17,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 180/200 [02:26<00:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 181/200 [02:27<00:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 182/200 [02:28<00:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 183/200 [02:29<00:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 184/200 [02:30<00:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▎| 185/200 [02:31<00:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 186/200 [02:31<00:11,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▎| 187/200 [02:32<00:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 188/200 [02:33<00:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 189/200 [02:34<00:08,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▌| 190/200 [02:35<00:08,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 191/200 [02:35<00:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 192/200 [02:36<00:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▋| 193/200 [02:37<00:05,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 194/200 [02:38<00:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 195/200 [02:39<00:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 196/200 [02:40<00:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 197/200 [02:40<00:02,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 198/200 [02:41<00:01,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|█████████▉| 199/200 [02:42<00:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|██████████| 200/200 [02:43<00:00,  1.22it/s]100%|██████████| 200/200 [02:43<00:00,  1.22it/s]
tensor(1.8011, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8276, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6901, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7085, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6999, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7215, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6861, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7157, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7877, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7472, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7420, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7635, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6832, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8877, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7567, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7047, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6736, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7119, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6971, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8967, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7099, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6548, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7462, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7339, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6978, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6650, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7604, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6672, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6436, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6797, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7484, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8259, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7422, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7215, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6684, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7202, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7540, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6720, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7575, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6959, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7034, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7162, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7593, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7133, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7175, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6893, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7233, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7321, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8199, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6839, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6448, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7524, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6889, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7266, device='cuda:0', grad_fn=<AddBackward0>)
  0%|          | 0/50 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  2%|▏         | 1/50 [00:14<11:34, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  4%|▍         | 2/50 [00:28<11:20, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  6%|▌         | 3/50 [00:42<11:05, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  8%|▊         | 4/50 [00:56<10:52, 14.18s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 10%|█         | 5/50 [01:10<10:37, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 12%|█▏        | 6/50 [01:25<10:23, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 14%|█▍        | 7/50 [01:39<10:09, 14.18s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 16%|█▌        | 8/50 [01:53<09:55, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 18%|█▊        | 9/50 [02:07<09:40, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 20%|██        | 10/50 [02:21<09:26, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 22%|██▏       | 11/50 [02:35<09:12, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 24%|██▍       | 12/50 [02:50<08:58, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 26%|██▌       | 13/50 [03:04<08:44, 14.18s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 28%|██▊       | 14/50 [03:18<08:30, 14.18s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 30%|███       | 15/50 [03:32<08:15, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 32%|███▏      | 16/50 [03:46<08:01, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 34%|███▍      | 17/50 [04:00<07:47, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 36%|███▌      | 18/50 [04:15<07:33, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 38%|███▊      | 19/50 [04:29<07:19, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 40%|████      | 20/50 [04:43<07:04, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 42%|████▏     | 21/50 [04:57<06:50, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 44%|████▍     | 22/50 [05:11<06:36, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 46%|████▌     | 23/50 [05:25<06:22, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 48%|████▊     | 24/50 [05:39<06:08, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 50%|█████     | 25/50 [05:54<05:53, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 52%|█████▏    | 26/50 [06:08<05:39, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 54%|█████▍    | 27/50 [06:22<05:25, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 56%|█████▌    | 28/50 [06:36<05:11, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 58%|█████▊    | 29/50 [06:50<04:57, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 60%|██████    | 30/50 [07:04<04:42, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 62%|██████▏   | 31/50 [07:19<04:28, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 64%|██████▍   | 32/50 [07:33<04:14, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 66%|██████▌   | 33/50 [07:47<04:00, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 68%|██████▊   | 34/50 [08:01<03:46, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 70%|███████   | 35/50 [08:15<03:32, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 72%|███████▏  | 36/50 [08:29<03:18, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 74%|███████▍  | 37/50 [08:43<03:03, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 76%|███████▌  | 38/50 [08:58<02:49, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 78%|███████▊  | 39/50 [09:12<02:35, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 80%|████████  | 40/50 [09:26<02:21, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 82%|████████▏ | 41/50 [09:40<02:07, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 84%|████████▍ | 42/50 [09:54<01:53, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 86%|████████▌ | 43/50 [10:08<01:39, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 88%|████████▊ | 44/50 [10:22<01:24, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 90%|█████████ | 45/50 [10:37<01:10, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 92%|█████████▏| 46/50 [10:51<00:56, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 94%|█████████▍| 47/50 [11:05<00:42, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 96%|█████████▌| 48/50 [11:19<00:28, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 98%|█████████▊| 49/50 [11:33<00:14, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
100%|██████████| 50/50 [11:48<00:00, 14.22s/it]100%|██████████| 50/50 [11:48<00:00, 14.16s/it]k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing 
transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/400 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 1/400 [00:00<05:21,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 2/400 [00:01<05:20,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 3/400 [00:02<05:23,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 4/400 [00:03<05:22,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|▏         | 5/400 [00:04<05:21,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 6/400 [00:04<05:20,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 7/400 [00:05<05:19,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 8/400 [00:06<05:19,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 9/400 [00:07<05:18,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▎         | 10/400 [00:08<05:17,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 11/400 [00:08<05:16,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 12/400 [00:09<05:15,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 13/400 [00:10<05:14,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▎         | 14/400 [00:11<05:14,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 15/400 [00:12<05:13,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 16/400 [00:13<05:13,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 17/400 [00:13<05:12,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 18/400 [00:14<05:11,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▍         | 19/400 [00:15<05:10,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▌         | 20/400 [00:16<05:10,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▌         | 21/400 [00:17<05:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 22/400 [00:17<05:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 23/400 [00:18<05:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 24/400 [00:19<05:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▋         | 25/400 [00:20<05:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▋         | 26/400 [00:21<05:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 27/400 [00:22<05:07,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 28/400 [00:22<05:06,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 29/400 [00:23<05:06,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 30/400 [00:24<05:05,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 31/400 [00:25<05:05,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 32/400 [00:26<05:05,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 33/400 [00:27<05:04,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 34/400 [00:27<05:03,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 35/400 [00:28<05:02,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 36/400 [00:29<05:02,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 37/400 [00:30<05:01,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|▉         | 38/400 [00:31<05:00,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|▉         | 39/400 [00:32<04:59,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 40/400 [00:32<04:59,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 41/400 [00:33<04:58,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 42/400 [00:34<04:58,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 43/400 [00:35<04:58,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 44/400 [00:36<04:57,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█▏        | 45/400 [00:37<04:56,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 46/400 [00:37<04:55,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 47/400 [00:38<04:54,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 48/400 [00:39<04:53,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 49/400 [00:40<04:52,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▎        | 50/400 [00:41<04:51,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 51/400 [00:42<04:50,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 52/400 [00:42<04:49,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 53/400 [00:43<04:48,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▎        | 54/400 [00:44<04:47,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 55/400 [00:45<04:46,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 56/400 [00:46<04:45,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 57/400 [00:46<04:45,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 58/400 [00:47<04:43,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▍        | 59/400 [00:48<04:42,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▌        | 60/400 [00:49<04:42,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▌        | 61/400 [00:50<04:41,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 62/400 [00:51<04:40,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 63/400 [00:51<04:39,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 64/400 [00:52<04:38,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▋        | 65/400 [00:53<04:37,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▋        | 66/400 [00:54<04:36,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 67/400 [00:55<04:35,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 68/400 [00:56<04:34,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 69/400 [00:56<04:33,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 70/400 [00:57<04:32,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 71/400 [00:58<04:31,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 72/400 [00:59<04:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 73/400 [01:00<04:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 74/400 [01:01<04:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 75/400 [01:01<04:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 76/400 [01:02<04:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 77/400 [01:03<04:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|█▉        | 78/400 [01:04<04:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|█▉        | 79/400 [01:05<04:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 80/400 [01:05<04:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 81/400 [01:06<04:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 82/400 [01:07<04:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 83/400 [01:08<04:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 84/400 [01:09<04:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██▏       | 85/400 [01:10<04:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 86/400 [01:10<04:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 87/400 [01:11<04:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 88/400 [01:12<04:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 89/400 [01:13<04:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▎       | 90/400 [01:14<04:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 91/400 [01:14<04:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 92/400 [01:15<04:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 93/400 [01:16<04:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▎       | 94/400 [01:17<04:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 95/400 [01:18<04:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 96/400 [01:19<04:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 97/400 [01:19<04:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 98/400 [01:20<04:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▍       | 99/400 [01:21<04:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▌       | 100/400 [01:22<04:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▌       | 101/400 [01:23<04:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 102/400 [01:23<04:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 103/400 [01:24<04:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 104/400 [01:25<04:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▋       | 105/400 [01:26<04:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▋       | 106/400 [01:27<04:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 107/400 [01:28<03:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 108/400 [01:28<03:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 109/400 [01:29<03:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 110/400 [01:30<03:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 111/400 [01:31<03:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 112/400 [01:32<03:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 113/400 [01:32<03:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 114/400 [01:33<03:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 115/400 [01:34<03:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 116/400 [01:35<03:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 117/400 [01:36<03:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|██▉       | 118/400 [01:37<03:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|██▉       | 119/400 [01:37<03:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 120/400 [01:38<03:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 121/400 [01:39<03:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 122/400 [01:40<03:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 123/400 [01:41<03:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 124/400 [01:41<03:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███▏      | 125/400 [01:42<03:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 126/400 [01:43<03:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 127/400 [01:44<03:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 128/400 [01:45<03:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 129/400 [01:46<03:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▎      | 130/400 [01:46<03:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 131/400 [01:47<03:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 132/400 [01:48<03:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 133/400 [01:49<03:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▎      | 134/400 [01:50<03:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 135/400 [01:50<03:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 136/400 [01:51<03:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 137/400 [01:52<03:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 138/400 [01:53<03:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▍      | 139/400 [01:54<03:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▌      | 140/400 [01:54<03:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▌      | 141/400 [01:55<03:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 142/400 [01:56<03:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 143/400 [01:57<03:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 144/400 [01:58<03:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▋      | 145/400 [01:59<03:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▋      | 146/400 [01:59<03:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
tensor(7.7737, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.1635, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.6418, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.9404, device='cuda:0', grad_fn=<AddBackward0>)
tensor(9.1817, device='cuda:0', grad_fn=<AddBackward0>)
tensor(9.8006, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.9875, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.0750, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.2027, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.0060, device='cuda:0', grad_fn=<AddBackward0>)
tensor(9.3419, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.0268, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.4148, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.7593, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.1519, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.3111, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.1651, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.6853, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.1256, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.2403, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.3892, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.0105, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.5159, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.3685, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.6706, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.4515, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.4645, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.8515, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.6777, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.2824, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.8457, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.7981, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.0513, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.2593, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.7245, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.3617, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.8234, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.8065, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.3360, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.9373, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.4763, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.4255, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.9231, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4730, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4390, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.5248, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.5068, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.6849, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.6641, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.5519, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4020, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4338, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2071, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2708, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3135, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.5370, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0829, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0533, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4158, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2687, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3292, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0129, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2260, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1507, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1122, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0322, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0675, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1300, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3288, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9328, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9346, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0613, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8832, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9444, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9569, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0344, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2031, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9365, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9852, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9848, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0389, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8946, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9763, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0394, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8373, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0517, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0292, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0979, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9777, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8455, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9523, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8062, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8230, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8301, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9053, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9067, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8480, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7810, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7783, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8051, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7653, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9049, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0122, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7942, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8221, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8470, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7685, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8727, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9296, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7994, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7497, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7014, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7027, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8466, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8129, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8432, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7517, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7773, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8034, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7690, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8177, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7387, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7689, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7682, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6811, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6821, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7536, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7032, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7488, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7279, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7200, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7352, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8139, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8417, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7475, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7406, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9245, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7214, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8191, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6829, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7468, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6627, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8681, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7204, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8445, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6258, device='cuda:0', grad_fn=<AddBackward0>)
 37%|███▋      | 147/400 [02:00<03:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 148/400 [02:01<03:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 149/400 [02:02<03:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 150/400 [02:03<03:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 151/400 [02:03<03:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 152/400 [02:04<03:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 153/400 [02:05<03:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 154/400 [02:06<03:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 155/400 [02:07<03:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 156/400 [02:08<03:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 157/400 [02:08<03:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|███▉      | 158/400 [02:09<03:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|███▉      | 159/400 [02:10<03:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 160/400 [02:11<03:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 161/400 [02:12<03:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 162/400 [02:12<03:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 163/400 [02:13<03:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 164/400 [02:14<03:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████▏     | 165/400 [02:15<03:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 166/400 [02:16<03:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 167/400 [02:17<03:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 168/400 [02:17<03:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 169/400 [02:18<03:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▎     | 170/400 [02:19<03:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 171/400 [02:20<03:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 172/400 [02:21<03:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 173/400 [02:21<03:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▎     | 174/400 [02:22<03:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 175/400 [02:23<03:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 176/400 [02:24<03:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 177/400 [02:25<03:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 178/400 [02:26<03:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▍     | 179/400 [02:26<03:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▌     | 180/400 [02:27<02:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▌     | 181/400 [02:28<02:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 182/400 [02:29<02:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 183/400 [02:30<02:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 184/400 [02:30<02:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▋     | 185/400 [02:31<02:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▋     | 186/400 [02:32<02:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 187/400 [02:33<02:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 188/400 [02:34<02:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 189/400 [02:35<02:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 190/400 [02:35<02:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 191/400 [02:36<02:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 192/400 [02:37<02:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 193/400 [02:38<02:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 194/400 [02:39<02:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 195/400 [02:39<02:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 196/400 [02:40<02:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 197/400 [02:41<02:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|████▉     | 198/400 [02:42<02:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|████▉     | 199/400 [02:43<02:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 200/400 [02:44<02:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 201/400 [02:44<02:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 202/400 [02:45<02:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 203/400 [02:46<02:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 204/400 [02:47<02:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████▏    | 205/400 [02:48<02:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 206/400 [02:48<02:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 207/400 [02:49<02:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 208/400 [02:50<02:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 209/400 [02:51<02:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▎    | 210/400 [02:52<02:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 211/400 [02:52<02:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 212/400 [02:53<02:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 213/400 [02:54<02:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▎    | 214/400 [02:55<02:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 215/400 [02:56<02:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 216/400 [02:57<02:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 217/400 [02:57<02:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▍    | 218/400 [02:58<02:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▍    | 219/400 [02:59<02:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▌    | 220/400 [03:00<02:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▌    | 221/400 [03:01<02:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 222/400 [03:01<02:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 223/400 [03:02<02:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 224/400 [03:03<02:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▋    | 225/400 [03:04<02:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▋    | 226/400 [03:05<02:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 227/400 [03:06<02:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 228/400 [03:06<02:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 229/400 [03:07<02:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▊    | 230/400 [03:08<02:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 231/400 [03:09<02:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 232/400 [03:10<02:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 233/400 [03:10<02:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 234/400 [03:11<02:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 235/400 [03:12<02:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 236/400 [03:13<02:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 237/400 [03:14<02:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|█████▉    | 238/400 [03:15<02:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|█████▉    | 239/400 [03:15<02:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 240/400 [03:16<02:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 241/400 [03:17<02:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 242/400 [03:18<02:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 243/400 [03:19<02:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 244/400 [03:19<02:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████▏   | 245/400 [03:20<02:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 246/400 [03:21<02:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 247/400 [03:22<02:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 248/400 [03:23<02:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 249/400 [03:24<02:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▎   | 250/400 [03:24<02:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 251/400 [03:25<02:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 252/400 [03:26<02:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 253/400 [03:27<02:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▎   | 254/400 [03:28<01:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 255/400 [03:28<01:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 256/400 [03:29<01:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 257/400 [03:30<01:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 258/400 [03:31<01:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▍   | 259/400 [03:32<01:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▌   | 260/400 [03:33<01:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▌   | 261/400 [03:33<01:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 262/400 [03:34<01:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 263/400 [03:35<01:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 264/400 [03:36<01:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▋   | 265/400 [03:37<01:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▋   | 266/400 [03:37<01:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 267/400 [03:38<01:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 268/400 [03:39<01:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 269/400 [03:40<01:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 270/400 [03:41<01:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 271/400 [03:42<01:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 272/400 [03:42<01:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 273/400 [03:43<01:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 274/400 [03:44<01:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 275/400 [03:45<01:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 276/400 [03:46<01:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 277/400 [03:46<01:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|██████▉   | 278/400 [03:47<01:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|██████▉   | 279/400 [03:48<01:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 280/400 [03:49<01:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 281/400 [03:50<01:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 282/400 [03:51<01:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 283/400 [03:51<01:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 284/400 [03:52<01:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████▏  | 285/400 [03:53<01:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 286/400 [03:54<01:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 287/400 [03:55<01:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 288/400 [03:55<01:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 289/400 [03:56<01:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▎  | 290/400 [03:57<01:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 291/400 [03:58<01:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 292/400 [03:59<01:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
tensor(1.6878, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6462, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6442, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6901, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6833, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6686, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6357, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6229, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6396, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6781, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7421, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7224, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6824, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7160, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6462, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6212, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7073, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7509, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8034, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6099, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6403, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6901, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6613, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6742, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7554, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7455, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7003, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6717, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7057, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7582, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6881, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6592, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6768, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6235, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6723, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6660, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6437, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6429, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6253, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6746, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7735, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6987, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6914, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6121, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6460, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6580, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6301, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6506, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6612, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6302, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7724, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7276, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7389, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6430, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6939, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6111, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6506, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6747, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6524, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6438, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6216, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6011, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6711, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6818, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6752, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6512, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6529, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6336, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6724, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6701, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6430, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6229, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6141, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6324, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6325, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6136, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6001, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5998, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6388, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6223, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6722, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6128, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6362, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7080, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5997, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6163, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6427, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6081, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6148, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6176, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6985, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6080, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6461, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6364, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6046, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6217, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6165, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6410, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6762, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6449, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6248, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6373, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6223, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6977, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6149, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6323, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6426, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6047, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6011, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6114, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5844, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5931, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6092, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6339, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5807, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5784, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6068, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5990, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6429, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7173, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6202, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6120, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5936, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6755, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6498, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6262, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6095, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6061, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6030, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5982, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5934, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5951, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5913, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6244, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6127, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6394, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5813, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6305, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6186, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6201, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5922, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6490, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6147, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6216, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6003, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5963, device='cuda:0', grad_fn=<AddBackward0>)
 73%|███████▎  | 293/400 [03:59<01:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▎  | 294/400 [04:00<01:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 295/400 [04:01<01:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 296/400 [04:02<01:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 297/400 [04:03<01:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 298/400 [04:04<01:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▍  | 299/400 [04:04<01:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▌  | 300/400 [04:05<01:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▌  | 301/400 [04:06<01:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 302/400 [04:07<01:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 303/400 [04:08<01:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 304/400 [04:08<01:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▋  | 305/400 [04:09<01:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▋  | 306/400 [04:10<01:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 307/400 [04:11<01:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 308/400 [04:12<01:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 309/400 [04:13<01:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 310/400 [04:13<01:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 311/400 [04:14<01:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 312/400 [04:15<01:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 313/400 [04:16<01:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 314/400 [04:17<01:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 315/400 [04:17<01:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 316/400 [04:18<01:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 317/400 [04:19<01:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|███████▉  | 318/400 [04:20<01:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|███████▉  | 319/400 [04:21<01:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 320/400 [04:22<01:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 321/400 [04:22<01:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 322/400 [04:23<01:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 323/400 [04:24<01:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 324/400 [04:25<01:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████▏ | 325/400 [04:26<01:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 326/400 [04:26<01:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 327/400 [04:27<00:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 328/400 [04:28<00:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 329/400 [04:29<00:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▎ | 330/400 [04:30<00:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 331/400 [04:31<00:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 332/400 [04:31<00:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 333/400 [04:32<00:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▎ | 334/400 [04:33<00:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 335/400 [04:34<00:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 336/400 [04:35<00:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 337/400 [04:35<00:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 338/400 [04:36<00:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▍ | 339/400 [04:37<00:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▌ | 340/400 [04:38<00:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▌ | 341/400 [04:39<00:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 342/400 [04:40<00:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 343/400 [04:40<00:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 344/400 [04:41<00:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▋ | 345/400 [04:42<00:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▋ | 346/400 [04:43<00:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 347/400 [04:44<00:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 348/400 [04:44<00:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 349/400 [04:45<00:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 350/400 [04:46<00:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 351/400 [04:47<00:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 352/400 [04:48<00:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 353/400 [04:49<00:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 354/400 [04:49<00:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 355/400 [04:50<00:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 356/400 [04:51<00:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 357/400 [04:52<00:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|████████▉ | 358/400 [04:53<00:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|████████▉ | 359/400 [04:53<00:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 360/400 [04:54<00:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 361/400 [04:55<00:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 362/400 [04:56<00:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 363/400 [04:57<00:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 364/400 [04:58<00:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████▏| 365/400 [04:58<00:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 366/400 [04:59<00:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 367/400 [05:00<00:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 368/400 [05:01<00:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 369/400 [05:02<00:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▎| 370/400 [05:02<00:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 371/400 [05:03<00:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 372/400 [05:04<00:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 373/400 [05:05<00:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▎| 374/400 [05:06<00:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 375/400 [05:06<00:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 376/400 [05:07<00:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 377/400 [05:08<00:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 378/400 [05:09<00:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▍| 379/400 [05:10<00:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▌| 380/400 [05:11<00:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▌| 381/400 [05:11<00:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 382/400 [05:12<00:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 383/400 [05:13<00:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 384/400 [05:14<00:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▋| 385/400 [05:15<00:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▋| 386/400 [05:15<00:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 387/400 [05:16<00:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 388/400 [05:17<00:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 389/400 [05:18<00:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 390/400 [05:19<00:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 391/400 [05:20<00:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 392/400 [05:20<00:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 393/400 [05:21<00:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 394/400 [05:22<00:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 395/400 [05:23<00:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 396/400 [05:24<00:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 397/400 [05:24<00:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|█████████▉| 398/400 [05:25<00:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|█████████▉| 399/400 [05:26<00:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|██████████| 400/400 [05:27<00:00,  1.22it/s]100%|██████████| 400/400 [05:27<00:00,  1.22it/s]
tensor(1.6064, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6054, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6113, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6139, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6324, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6161, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6407, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6367, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6078, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5855, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5791, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5943, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6249, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6491, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6080, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6028, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5794, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5892, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6001, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5794, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6008, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5980, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5653, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5874, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5741, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5741, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5950, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6268, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6192, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5706, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5960, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6022, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6006, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6363, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6037, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5993, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6109, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6175, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6056, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6117, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6353, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6146, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5822, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6339, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6106, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5909, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6061, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6229, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6042, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5770, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5824, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5941, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6205, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5817, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5736, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6250, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5818, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6055, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6004, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6044, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5862, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5835, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5923, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5860, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6007, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5691, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5779, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5829, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5835, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5828, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5794, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5845, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5725, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5653, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5686, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5860, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6200, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5820, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5958, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5827, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5771, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5758, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5782, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5836, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6263, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5638, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5734, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6114, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6053, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6126, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5802, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5949, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5805, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5768, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5881, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6184, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6001, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5914, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5645, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6040, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6103, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5832, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6043, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6154, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6052, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5863, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5707, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5812, device='cuda:0', grad_fn=<AddBackward0>)
  0%|          | 0/50 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  2%|▏         | 1/50 [00:14<11:36, 14.21s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  4%|▍         | 2/50 [00:28<11:20, 14.18s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  6%|▌         | 3/50 [00:42<11:05, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  8%|▊         | 4/50 [00:56<10:51, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 10%|█         | 5/50 [01:10<10:37, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 12%|█▏        | 6/50 [01:25<10:23, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 14%|█▍        | 7/50 [01:39<10:08, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 16%|█▌        | 8/50 [01:53<09:54, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 18%|█▊        | 9/50 [02:07<09:40, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 20%|██        | 10/50 [02:21<09:26, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 22%|██▏       | 11/50 [02:35<09:11, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 24%|██▍       | 12/50 [02:49<08:57, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 26%|██▌       | 13/50 [03:04<08:43, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 28%|██▊       | 14/50 [03:18<08:29, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 30%|███       | 15/50 [03:32<08:15, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 32%|███▏      | 16/50 [03:46<08:01, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 34%|███▍      | 17/50 [04:00<07:46, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 36%|███▌      | 18/50 [04:14<07:32, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 38%|███▊      | 19/50 [04:28<07:18, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 40%|████      | 20/50 [04:43<07:04, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 42%|████▏     | 21/50 [04:57<06:50, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 44%|████▍     | 22/50 [05:11<06:36, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 46%|████▌     | 23/50 [05:25<06:22, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 48%|████▊     | 24/50 [05:39<06:07, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 50%|█████     | 25/50 [05:53<05:53, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 52%|█████▏    | 26/50 [06:08<05:39, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 54%|█████▍    | 27/50 [06:22<05:25, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 56%|█████▌    | 28/50 [06:36<05:11, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 58%|█████▊    | 29/50 [06:50<04:57, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 60%|██████    | 30/50 [07:04<04:42, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 62%|██████▏   | 31/50 [07:18<04:28, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 64%|██████▍   | 32/50 [07:32<04:14, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 66%|██████▌   | 33/50 [07:47<04:00, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 68%|██████▊   | 34/50 [08:01<03:46, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 70%|███████   | 35/50 [08:15<03:32, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 72%|███████▏  | 36/50 [08:29<03:17, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 74%|███████▍  | 37/50 [08:43<03:03, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 76%|███████▌  | 38/50 [08:57<02:49, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 78%|███████▊  | 39/50 [09:11<02:35, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 80%|████████  | 40/50 [09:25<02:21, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 82%|████████▏ | 41/50 [09:40<02:07, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 84%|████████▍ | 42/50 [09:54<01:53, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 86%|████████▌ | 43/50 [10:08<01:39, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 88%|████████▊ | 44/50 [10:22<01:24, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 90%|█████████ | 45/50 [10:36<01:10, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 92%|█████████▏| 46/50 [10:50<00:56, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 94%|█████████▍| 47/50 [11:05<00:42, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 96%|█████████▌| 48/50 [11:19<00:28, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 98%|█████████▊| 49/50 [11:33<00:14, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
100%|██████████| 50/50 [11:47<00:00, 14.14s/it]100%|██████████| 50/50 [11:47<00:00, 14.15s/it]k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing 
transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/700 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 1/700 [00:00<09:21,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 2/700 [00:01<09:21,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 3/700 [00:02<09:27,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 4/700 [00:03<09:26,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 5/700 [00:04<09:25,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 6/700 [00:04<09:24,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 7/700 [00:05<09:23,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 8/700 [00:06<09:23,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|▏         | 9/700 [00:07<09:22,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|▏         | 10/700 [00:08<09:21,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 11/700 [00:08<09:20,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 12/700 [00:09<09:19,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 13/700 [00:10<09:18,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 14/700 [00:11<09:18,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 15/700 [00:12<09:18,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 16/700 [00:13<09:17,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 17/700 [00:13<09:17,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 18/700 [00:14<09:16,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 19/700 [00:15<09:15,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 20/700 [00:16<09:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 21/700 [00:17<09:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 22/700 [00:17<09:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 23/700 [00:18<09:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 24/700 [00:19<09:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▎         | 25/700 [00:20<09:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▎         | 26/700 [00:21<09:16,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 27/700 [00:22<09:15,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 28/700 [00:22<09:15,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 29/700 [00:23<09:15,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 30/700 [00:24<09:15,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 31/700 [00:25<09:14,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▍         | 32/700 [00:26<09:15,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▍         | 33/700 [00:27<09:15,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▍         | 34/700 [00:27<09:14,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▌         | 35/700 [00:28<09:15,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▌         | 36/700 [00:29<09:14,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▌         | 37/700 [00:30<09:14,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▌         | 38/700 [00:31<09:13,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 39/700 [00:32<09:11,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 40/700 [00:32<09:11,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 41/700 [00:33<09:11,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 42/700 [00:34<09:10,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 43/700 [00:35<09:09,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▋         | 44/700 [00:36<09:09,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▋         | 45/700 [00:37<09:07,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 46/700 [00:37<09:05,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 47/700 [00:38<09:04,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 48/700 [00:39<09:02,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 49/700 [00:40<09:01,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 50/700 [00:41<09:00,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 51/700 [00:42<08:59,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 52/700 [00:42<08:58,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 53/700 [00:43<08:57,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 54/700 [00:44<08:55,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 55/700 [00:45<08:53,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 56/700 [00:46<08:52,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 57/700 [00:47<08:50,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 58/700 [00:47<08:49,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 59/700 [00:48<08:48,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▊         | 60/700 [00:49<08:47,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▊         | 61/700 [00:50<08:47,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 62/700 [00:51<08:45,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 63/700 [00:51<08:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 64/700 [00:52<08:44,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 65/700 [00:53<08:42,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 66/700 [00:54<08:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|▉         | 67/700 [00:55<08:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|▉         | 68/700 [00:56<08:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|▉         | 69/700 [00:56<08:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 70/700 [00:57<08:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 71/700 [00:58<08:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 72/700 [00:59<08:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 73/700 [01:00<08:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 74/700 [01:00<08:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 75/700 [01:01<08:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 76/700 [01:02<08:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 77/700 [01:03<08:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 78/700 [01:04<08:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█▏        | 79/700 [01:05<08:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█▏        | 80/700 [01:05<08:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 81/700 [01:06<08:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 82/700 [01:07<08:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 83/700 [01:08<08:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 84/700 [01:09<08:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 85/700 [01:09<08:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 86/700 [01:10<08:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 87/700 [01:11<08:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 88/700 [01:12<08:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 89/700 [01:13<08:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 90/700 [01:14<08:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 91/700 [01:14<08:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 92/700 [01:15<08:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 93/700 [01:16<08:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 94/700 [01:17<08:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▎        | 95/700 [01:18<08:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▎        | 96/700 [01:18<08:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 97/700 [01:19<08:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 98/700 [01:20<08:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 99/700 [01:21<08:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 100/700 [01:22<08:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 101/700 [01:23<08:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▍        | 102/700 [01:23<08:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▍        | 103/700 [01:24<08:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▍        | 104/700 [01:25<08:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▌        | 105/700 [01:26<08:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▌        | 106/700 [01:27<08:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▌        | 107/700 [01:27<08:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▌        | 108/700 [01:28<08:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 109/700 [01:29<08:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 110/700 [01:30<08:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 111/700 [01:31<08:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 112/700 [01:32<08:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 113/700 [01:32<07:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▋        | 114/700 [01:33<07:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▋        | 115/700 [01:34<07:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 116/700 [01:35<07:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 117/700 [01:36<07:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 118/700 [01:36<07:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 119/700 [01:37<07:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 120/700 [01:38<07:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 121/700 [01:39<07:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 122/700 [01:40<07:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 123/700 [01:41<07:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 124/700 [01:41<07:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 125/700 [01:42<07:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 126/700 [01:43<07:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 127/700 [01:44<07:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 128/700 [01:45<07:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 129/700 [01:45<07:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▊        | 130/700 [01:46<07:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▊        | 131/700 [01:47<07:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 132/700 [01:48<07:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 133/700 [01:49<07:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 134/700 [01:50<07:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 135/700 [01:50<07:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 136/700 [01:51<07:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|█▉        | 137/700 [01:52<07:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|█▉        | 138/700 [01:53<07:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|█▉        | 139/700 [01:54<07:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 140/700 [01:54<07:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 141/700 [01:55<07:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 142/700 [01:56<07:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 143/700 [01:57<07:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 144/700 [01:58<07:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 145/700 [01:58<07:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 146/700 [01:59<07:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
tensor(8.8446, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.2053, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.1736, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.8920, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.9028, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.7201, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.7553, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.1563, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.6624, device='cuda:0', grad_fn=<AddBackward0>)
tensor(9.0316, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.9461, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.3745, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.8549, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.9212, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.8901, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.2817, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.6792, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.4316, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.6719, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.8138, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.2383, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.3827, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.7316, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.5165, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.4149, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.4138, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.4732, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.2916, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.4019, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.2994, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.8646, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.5140, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.5361, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.9852, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.1577, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.0096, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.3135, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.1429, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.7177, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.7125, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.9635, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.3083, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.2143, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.0418, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.9326, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.9679, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.4198, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.6828, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.1178, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.8927, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.4289, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.2211, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.9014, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.6927, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.9237, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4220, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.6317, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.6783, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.7052, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.0388, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.8167, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4924, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.5120, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3384, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2216, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4807, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3116, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2056, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1590, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0546, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2370, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3839, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4436, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9823, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9769, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1651, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1771, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9111, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9837, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1311, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1216, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8813, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0206, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8751, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9231, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9076, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0014, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8137, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0060, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8762, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9015, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1876, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8835, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8321, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9139, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1345, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7926, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9523, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8352, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7521, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8645, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0092, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9153, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8685, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8373, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7613, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8375, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9180, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8802, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8641, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8859, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7550, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7431, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7746, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6815, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7999, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7580, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8285, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7640, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8705, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6467, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7123, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7320, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8854, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9251, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6945, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7259, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7919, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7391, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6684, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6881, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8097, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7672, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7898, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7095, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7394, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6967, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8650, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6658, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7186, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7055, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6737, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6333, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6328, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8542, device='cuda:0', grad_fn=<AddBackward0>)
 21%|██        | 147/700 [02:00<07:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 148/700 [02:01<07:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██▏       | 149/700 [02:02<07:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██▏       | 150/700 [02:03<07:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 151/700 [02:03<07:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 152/700 [02:04<07:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 153/700 [02:05<07:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 154/700 [02:06<07:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 155/700 [02:07<07:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 156/700 [02:07<07:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 157/700 [02:08<07:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 158/700 [02:09<07:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 159/700 [02:10<07:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 160/700 [02:11<07:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 161/700 [02:12<07:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 162/700 [02:12<07:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 163/700 [02:13<07:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 164/700 [02:14<07:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▎       | 165/700 [02:15<07:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▎       | 166/700 [02:16<07:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 167/700 [02:16<07:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 168/700 [02:17<07:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 169/700 [02:18<07:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 170/700 [02:19<07:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 171/700 [02:20<07:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▍       | 172/700 [02:21<07:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▍       | 173/700 [02:21<07:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▍       | 174/700 [02:22<07:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▌       | 175/700 [02:23<07:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▌       | 176/700 [02:24<07:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▌       | 177/700 [02:25<07:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▌       | 178/700 [02:25<07:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 179/700 [02:26<07:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 180/700 [02:27<07:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 181/700 [02:28<07:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 182/700 [02:29<07:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 183/700 [02:30<07:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▋       | 184/700 [02:30<07:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▋       | 185/700 [02:31<07:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 186/700 [02:32<07:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 187/700 [02:33<06:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 188/700 [02:34<06:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 189/700 [02:34<06:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 190/700 [02:35<06:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 191/700 [02:36<06:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 192/700 [02:37<06:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 193/700 [02:38<06:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 194/700 [02:39<06:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 195/700 [02:39<06:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 196/700 [02:40<06:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 197/700 [02:41<06:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 198/700 [02:42<06:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 199/700 [02:43<06:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▊       | 200/700 [02:43<06:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▊       | 201/700 [02:44<06:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 202/700 [02:45<06:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 203/700 [02:46<06:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 204/700 [02:47<06:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 205/700 [02:48<06:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 206/700 [02:48<06:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|██▉       | 207/700 [02:49<06:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|██▉       | 208/700 [02:50<06:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|██▉       | 209/700 [02:51<06:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 210/700 [02:52<06:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 211/700 [02:52<06:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 212/700 [02:53<06:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 213/700 [02:54<06:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 214/700 [02:55<06:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 215/700 [02:56<06:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 216/700 [02:57<06:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 217/700 [02:57<06:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 218/700 [02:58<06:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███▏      | 219/700 [02:59<06:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███▏      | 220/700 [03:00<06:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 221/700 [03:01<06:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 222/700 [03:01<06:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 223/700 [03:02<06:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 224/700 [03:03<06:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 225/700 [03:04<06:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 226/700 [03:05<06:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 227/700 [03:06<06:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 228/700 [03:06<06:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 229/700 [03:07<06:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 230/700 [03:08<06:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 231/700 [03:09<06:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 232/700 [03:10<06:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 233/700 [03:10<06:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 234/700 [03:11<06:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▎      | 235/700 [03:12<06:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▎      | 236/700 [03:13<06:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 237/700 [03:14<06:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 238/700 [03:14<06:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 239/700 [03:15<06:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 240/700 [03:16<06:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 241/700 [03:17<06:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▍      | 242/700 [03:18<06:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▍      | 243/700 [03:19<06:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▍      | 244/700 [03:19<06:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▌      | 245/700 [03:20<06:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▌      | 246/700 [03:21<06:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▌      | 247/700 [03:22<06:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▌      | 248/700 [03:23<06:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 249/700 [03:23<06:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 250/700 [03:24<06:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 251/700 [03:25<06:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 252/700 [03:26<06:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 253/700 [03:27<06:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▋      | 254/700 [03:28<06:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▋      | 255/700 [03:28<06:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 256/700 [03:29<06:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 257/700 [03:30<06:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 258/700 [03:31<06:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 259/700 [03:32<06:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 260/700 [03:32<05:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 261/700 [03:33<05:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 262/700 [03:34<05:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 263/700 [03:35<05:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 264/700 [03:36<05:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 265/700 [03:37<05:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 266/700 [03:37<05:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 267/700 [03:38<05:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 268/700 [03:39<05:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 269/700 [03:40<05:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▊      | 270/700 [03:41<05:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▊      | 271/700 [03:41<05:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 272/700 [03:42<05:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 273/700 [03:43<05:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 274/700 [03:44<05:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 275/700 [03:45<05:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 276/700 [03:46<05:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|███▉      | 277/700 [03:46<05:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|███▉      | 278/700 [03:47<05:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|███▉      | 279/700 [03:48<05:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 280/700 [03:49<05:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 281/700 [03:50<05:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 282/700 [03:50<05:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 283/700 [03:51<05:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 284/700 [03:52<05:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 285/700 [03:53<05:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 286/700 [03:54<05:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 287/700 [03:55<05:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 288/700 [03:55<05:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████▏     | 289/700 [03:56<05:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████▏     | 290/700 [03:57<05:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 291/700 [03:58<05:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 292/700 [03:59<05:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
tensor(1.9246, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7150, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6985, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7248, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6522, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7224, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7180, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7922, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6554, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6479, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6723, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6611, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6813, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6316, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7532, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7166, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6312, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6753, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6559, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6567, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7273, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7385, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6521, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6508, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6493, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6196, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7267, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6495, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6628, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5977, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6525, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6499, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6793, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7139, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6769, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7474, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6490, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7454, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6781, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6845, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6653, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6273, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6415, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6589, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6586, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6691, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6534, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6895, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7026, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6598, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6254, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6947, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6563, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6439, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6487, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5833, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6240, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6067, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6649, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6455, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6320, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6460, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6253, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6706, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6828, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6289, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6394, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6064, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6840, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6297, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6475, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6033, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6156, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6279, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6556, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5849, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6056, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5958, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6301, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6330, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6082, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6203, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6806, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6437, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6408, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6536, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6118, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6871, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5928, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6107, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5875, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6614, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6273, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6122, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7022, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6656, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6357, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6524, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6518, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5968, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6311, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6208, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6195, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6024, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6544, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6185, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6061, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5837, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6090, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6105, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5925, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6308, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6048, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6110, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5993, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6241, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6301, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6103, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6245, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5755, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5828, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6293, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5995, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5960, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6099, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6161, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6448, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5883, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6104, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6366, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5873, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5981, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6401, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6116, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5853, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6238, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6152, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6704, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6029, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5830, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5928, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6086, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6287, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6271, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5828, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5831, device='cuda:0', grad_fn=<AddBackward0>)
 42%|████▏     | 293/700 [03:59<05:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 294/700 [04:00<05:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 295/700 [04:01<05:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 296/700 [04:02<05:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 297/700 [04:03<05:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 298/700 [04:04<05:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 299/700 [04:04<05:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 300/700 [04:05<05:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 301/700 [04:06<05:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 302/700 [04:07<05:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 303/700 [04:08<05:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 304/700 [04:08<05:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▎     | 305/700 [04:09<05:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▎     | 306/700 [04:10<05:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 307/700 [04:11<05:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 308/700 [04:12<05:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 309/700 [04:13<05:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 310/700 [04:13<05:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 311/700 [04:14<05:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▍     | 312/700 [04:15<05:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▍     | 313/700 [04:16<05:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▍     | 314/700 [04:17<05:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▌     | 315/700 [04:17<05:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▌     | 316/700 [04:18<05:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▌     | 317/700 [04:19<05:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▌     | 318/700 [04:20<05:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 319/700 [04:21<05:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 320/700 [04:21<05:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 321/700 [04:22<05:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 322/700 [04:23<05:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 323/700 [04:24<05:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▋     | 324/700 [04:25<05:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▋     | 325/700 [04:26<05:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 326/700 [04:26<05:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 327/700 [04:27<05:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 328/700 [04:28<05:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 329/700 [04:29<05:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 330/700 [04:30<05:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 331/700 [04:30<05:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 332/700 [04:31<05:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 333/700 [04:32<04:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 334/700 [04:33<04:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 335/700 [04:34<04:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 336/700 [04:35<04:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 337/700 [04:35<04:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 338/700 [04:36<04:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 339/700 [04:37<04:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▊     | 340/700 [04:38<04:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▊     | 341/700 [04:39<04:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 342/700 [04:39<04:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 343/700 [04:40<04:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 344/700 [04:41<04:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 345/700 [04:42<04:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 346/700 [04:43<04:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|████▉     | 347/700 [04:44<04:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|████▉     | 348/700 [04:44<04:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|████▉     | 349/700 [04:45<04:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 350/700 [04:46<04:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 351/700 [04:47<04:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 352/700 [04:48<04:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 353/700 [04:48<04:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 354/700 [04:49<04:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 355/700 [04:50<04:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 356/700 [04:51<04:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 357/700 [04:52<04:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 358/700 [04:53<04:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████▏    | 359/700 [04:53<04:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████▏    | 360/700 [04:54<04:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 361/700 [04:55<04:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 362/700 [04:56<04:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 363/700 [04:57<04:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 364/700 [04:57<04:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 365/700 [04:58<04:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 366/700 [04:59<04:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 367/700 [05:00<04:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 368/700 [05:01<04:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 369/700 [05:02<04:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 370/700 [05:02<04:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 371/700 [05:03<04:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 372/700 [05:04<04:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 373/700 [05:05<04:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 374/700 [05:06<04:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▎    | 375/700 [05:06<04:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▎    | 376/700 [05:07<04:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 377/700 [05:08<04:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 378/700 [05:09<04:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 379/700 [05:10<04:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 380/700 [05:11<04:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 381/700 [05:11<04:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▍    | 382/700 [05:12<04:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▍    | 383/700 [05:13<04:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▍    | 384/700 [05:14<04:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▌    | 385/700 [05:15<04:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▌    | 386/700 [05:15<04:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▌    | 387/700 [05:16<04:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▌    | 388/700 [05:17<04:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 389/700 [05:18<04:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 390/700 [05:19<04:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 391/700 [05:20<04:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 392/700 [05:20<04:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 393/700 [05:21<04:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▋    | 394/700 [05:22<04:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▋    | 395/700 [05:23<04:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 396/700 [05:24<04:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 397/700 [05:24<04:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 398/700 [05:25<04:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 399/700 [05:26<04:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 400/700 [05:27<04:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 401/700 [05:28<04:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 402/700 [05:28<04:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 403/700 [05:29<04:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 404/700 [05:30<04:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 405/700 [05:31<04:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 406/700 [05:32<04:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 407/700 [05:33<03:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 408/700 [05:33<03:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 409/700 [05:34<03:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▊    | 410/700 [05:35<03:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▊    | 411/700 [05:36<03:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 412/700 [05:37<03:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 413/700 [05:37<03:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 414/700 [05:38<03:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 415/700 [05:39<03:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 416/700 [05:40<03:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|█████▉    | 417/700 [05:41<03:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|█████▉    | 418/700 [05:42<03:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|█████▉    | 419/700 [05:42<03:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 420/700 [05:43<03:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 421/700 [05:44<03:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 422/700 [05:45<03:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 423/700 [05:46<03:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 424/700 [05:46<03:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 425/700 [05:47<03:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 426/700 [05:48<03:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 427/700 [05:49<03:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 428/700 [05:50<03:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████▏   | 429/700 [05:51<03:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████▏   | 430/700 [05:51<03:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 431/700 [05:52<03:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 432/700 [05:53<03:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 433/700 [05:54<03:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 434/700 [05:55<03:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 435/700 [05:55<03:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 436/700 [05:56<03:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 437/700 [05:57<03:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 438/700 [05:58<03:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
tensor(1.6202, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5926, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6325, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6538, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6003, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5955, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6004, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6472, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5822, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5895, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5854, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6132, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5680, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5912, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6069, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5770, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5970, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5843, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6114, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5819, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6240, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5859, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6004, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6178, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6119, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5822, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6136, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6116, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5981, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6008, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6331, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5798, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5895, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6166, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5756, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5910, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5791, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5796, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6014, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5815, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6169, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6040, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6115, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6218, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5960, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5917, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6138, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6188, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5768, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5682, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6127, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5679, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5902, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5978, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6212, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5893, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5724, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5992, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5959, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5890, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5759, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5634, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5928, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6046, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5815, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5722, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5892, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5691, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5868, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5703, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5908, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5637, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5852, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5960, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5738, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5935, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6053, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5820, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5742, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5751, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6067, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6100, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5897, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5782, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5851, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5654, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5707, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6188, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5867, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5832, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5928, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5890, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6056, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5953, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6004, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5889, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5879, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5744, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5857, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5755, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5789, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5927, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5915, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6006, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5867, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5818, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5704, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5703, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5565, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5763, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5671, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5725, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5762, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5924, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5733, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5658, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5903, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5667, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5763, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5728, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5873, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5677, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5784, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5589, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5835, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5699, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5680, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5778, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6137, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5635, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5686, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5780, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5707, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5826, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5619, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5712, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5657, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5745, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5723, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5781, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5825, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5771, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5731, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5848, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5715, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5671, device='cuda:0', grad_fn=<AddBackward0>)
 63%|██████▎   | 439/700 [05:59<03:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 440/700 [06:00<03:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 441/700 [06:00<03:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 442/700 [06:01<03:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 443/700 [06:02<03:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 444/700 [06:03<03:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▎   | 445/700 [06:04<03:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▎   | 446/700 [06:04<03:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 447/700 [06:05<03:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 448/700 [06:06<03:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 449/700 [06:07<03:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 450/700 [06:08<03:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 451/700 [06:09<03:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▍   | 452/700 [06:09<03:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▍   | 453/700 [06:10<03:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▍   | 454/700 [06:11<03:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▌   | 455/700 [06:12<03:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▌   | 456/700 [06:13<03:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▌   | 457/700 [06:13<03:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▌   | 458/700 [06:14<03:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 459/700 [06:15<03:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 460/700 [06:16<03:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 461/700 [06:17<03:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 462/700 [06:18<03:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 463/700 [06:18<03:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▋   | 464/700 [06:19<03:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▋   | 465/700 [06:20<03:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 466/700 [06:21<03:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 467/700 [06:22<03:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 468/700 [06:22<03:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 469/700 [06:23<03:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 470/700 [06:24<03:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 471/700 [06:25<03:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 472/700 [06:26<03:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 473/700 [06:27<03:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 474/700 [06:27<03:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 475/700 [06:28<03:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 476/700 [06:29<03:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 477/700 [06:30<03:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 478/700 [06:31<03:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 479/700 [06:31<03:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▊   | 480/700 [06:32<02:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▊   | 481/700 [06:33<02:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 482/700 [06:34<02:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 483/700 [06:35<02:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 484/700 [06:36<02:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 485/700 [06:36<02:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 486/700 [06:37<02:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|██████▉   | 487/700 [06:38<02:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|██████▉   | 488/700 [06:39<02:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|██████▉   | 489/700 [06:40<02:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 490/700 [06:40<02:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 491/700 [06:41<02:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 492/700 [06:42<02:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 493/700 [06:43<02:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 494/700 [06:44<02:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 495/700 [06:45<02:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 496/700 [06:45<02:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 497/700 [06:46<02:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 498/700 [06:47<02:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████▏  | 499/700 [06:48<02:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████▏  | 500/700 [06:49<02:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 501/700 [06:49<02:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 502/700 [06:50<02:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 503/700 [06:51<02:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 504/700 [06:52<02:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 505/700 [06:53<02:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 506/700 [06:54<02:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 507/700 [06:54<02:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 508/700 [06:55<02:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 509/700 [06:56<02:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 510/700 [06:57<02:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 511/700 [06:58<02:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 512/700 [06:58<02:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 513/700 [06:59<02:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 514/700 [07:00<02:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▎  | 515/700 [07:01<02:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▎  | 516/700 [07:02<02:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 517/700 [07:03<02:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 518/700 [07:03<02:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 519/700 [07:04<02:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 520/700 [07:05<02:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 521/700 [07:06<02:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▍  | 522/700 [07:07<02:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▍  | 523/700 [07:07<02:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▍  | 524/700 [07:08<02:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▌  | 525/700 [07:09<02:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▌  | 526/700 [07:10<02:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▌  | 527/700 [07:11<02:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▌  | 528/700 [07:12<02:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 529/700 [07:12<02:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 530/700 [07:13<02:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 531/700 [07:14<02:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 532/700 [07:15<02:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 533/700 [07:16<02:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▋  | 534/700 [07:16<02:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▋  | 535/700 [07:17<02:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 536/700 [07:18<02:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 537/700 [07:19<02:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 538/700 [07:20<02:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 539/700 [07:20<02:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 540/700 [07:21<02:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 541/700 [07:22<02:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 542/700 [07:23<02:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 543/700 [07:24<02:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 544/700 [07:25<02:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 545/700 [07:25<02:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 546/700 [07:26<02:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 547/700 [07:27<02:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 548/700 [07:28<02:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 549/700 [07:29<02:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▊  | 550/700 [07:29<02:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▊  | 551/700 [07:30<02:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 552/700 [07:31<02:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 553/700 [07:32<02:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 554/700 [07:33<01:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 555/700 [07:34<01:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 556/700 [07:34<01:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|███████▉  | 557/700 [07:35<01:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|███████▉  | 558/700 [07:36<01:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|███████▉  | 559/700 [07:37<01:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 560/700 [07:38<01:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 561/700 [07:38<01:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 562/700 [07:39<01:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 563/700 [07:40<01:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 564/700 [07:41<01:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 565/700 [07:42<01:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 566/700 [07:43<01:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 567/700 [07:43<01:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 568/700 [07:44<01:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████▏ | 569/700 [07:45<01:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████▏ | 570/700 [07:46<01:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 571/700 [07:47<01:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 572/700 [07:47<01:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 573/700 [07:48<01:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 574/700 [07:49<01:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 575/700 [07:50<01:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 576/700 [07:51<01:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 577/700 [07:52<01:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 578/700 [07:52<01:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 579/700 [07:53<01:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 580/700 [07:54<01:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 581/700 [07:55<01:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 582/700 [07:56<01:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 583/700 [07:56<01:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 584/700 [07:57<01:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
tensor(1.5720, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5799, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5855, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5773, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6019, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5891, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5589, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5777, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5839, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5603, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6032, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5807, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5683, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5603, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5704, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5632, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5595, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5659, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5670, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5623, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5613, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5756, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5603, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5553, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5743, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5745, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5762, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5658, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5696, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5554, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5650, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5695, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5689, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5804, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5816, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5615, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5551, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5669, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5705, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5761, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5639, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5721, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5892, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5894, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5710, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5740, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5740, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5813, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5704, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5741, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5800, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5645, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5886, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5675, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5708, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5640, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5696, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5668, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5780, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5830, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5712, device='cuda:0', grad_fn=<AddBackward0>)
500
tensor(1.5760, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5627, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5528, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5627, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5590, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5738, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5563, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5665, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5635, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5569, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5584, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5674, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5537, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5568, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5570, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5763, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5564, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5592, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5692, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5565, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5613, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5669, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5576, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5625, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5646, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5781, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5673, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5492, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5651, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5676, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5641, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5753, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5557, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5533, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5709, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5654, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5754, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5707, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5616, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5617, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5613, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5739, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5577, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5731, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5583, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5589, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5828, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5743, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5625, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5656, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5626, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5553, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5620, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5639, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5554, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5469, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5642, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5554, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5446, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5589, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5571, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5515, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5561, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5555, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5509, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5597, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5620, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5607, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5693, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5604, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5546, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5594, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5552, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5537, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5613, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5624, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5658, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5565, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5577, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5739, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5614, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5532, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5668, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5600, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5589, device='cuda:0', grad_fn=<AddBackward0>)
 84%|████████▎ | 585/700 [07:58<01:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▎ | 586/700 [07:59<01:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 587/700 [08:00<01:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 588/700 [08:01<01:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 589/700 [08:01<01:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 590/700 [08:02<01:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 591/700 [08:03<01:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▍ | 592/700 [08:04<01:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▍ | 593/700 [08:05<01:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▍ | 594/700 [08:05<01:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▌ | 595/700 [08:06<01:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▌ | 596/700 [08:07<01:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▌ | 597/700 [08:08<01:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▌ | 598/700 [08:09<01:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 599/700 [08:10<01:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 600/700 [08:10<01:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 601/700 [08:11<01:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 602/700 [08:12<01:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 603/700 [08:13<01:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▋ | 604/700 [08:14<01:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▋ | 605/700 [08:14<01:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 606/700 [08:15<01:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 607/700 [08:16<01:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 608/700 [08:17<01:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 609/700 [08:18<01:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 610/700 [08:19<01:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 611/700 [08:19<01:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 612/700 [08:20<01:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 613/700 [08:21<01:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 614/700 [08:22<01:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 615/700 [08:23<01:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 616/700 [08:23<01:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 617/700 [08:24<01:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 618/700 [08:25<01:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 619/700 [08:26<01:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▊ | 620/700 [08:27<01:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▊ | 621/700 [08:28<01:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 622/700 [08:28<01:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 623/700 [08:29<01:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 624/700 [08:30<01:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 625/700 [08:31<01:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 626/700 [08:32<01:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|████████▉ | 627/700 [08:32<00:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|████████▉ | 628/700 [08:33<00:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|████████▉ | 629/700 [08:34<00:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 630/700 [08:35<00:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 631/700 [08:36<00:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 632/700 [08:36<00:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 633/700 [08:37<00:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 634/700 [08:38<00:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 635/700 [08:39<00:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 636/700 [08:40<00:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 637/700 [08:41<00:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 638/700 [08:41<00:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████▏| 639/700 [08:42<00:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████▏| 640/700 [08:43<00:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 641/700 [08:44<00:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 642/700 [08:45<00:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 643/700 [08:45<00:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 644/700 [08:46<00:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 645/700 [08:47<00:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 646/700 [08:48<00:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 647/700 [08:49<00:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 648/700 [08:50<00:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 649/700 [08:50<00:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 650/700 [08:51<00:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 651/700 [08:52<00:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 652/700 [08:53<00:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 653/700 [08:54<00:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 654/700 [08:54<00:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▎| 655/700 [08:55<00:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▎| 656/700 [08:56<00:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 657/700 [08:57<00:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 658/700 [08:58<00:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 659/700 [08:59<00:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 660/700 [08:59<00:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 661/700 [09:00<00:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▍| 662/700 [09:01<00:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▍| 663/700 [09:02<00:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▍| 664/700 [09:03<00:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▌| 665/700 [09:03<00:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▌| 666/700 [09:04<00:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▌| 667/700 [09:05<00:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▌| 668/700 [09:06<00:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 669/700 [09:07<00:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 670/700 [09:08<00:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 671/700 [09:08<00:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 672/700 [09:09<00:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 673/700 [09:10<00:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▋| 674/700 [09:11<00:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▋| 675/700 [09:12<00:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 676/700 [09:12<00:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 677/700 [09:13<00:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 678/700 [09:14<00:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 679/700 [09:15<00:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 680/700 [09:16<00:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 681/700 [09:17<00:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 682/700 [09:17<00:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 683/700 [09:18<00:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 684/700 [09:19<00:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 685/700 [09:20<00:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 686/700 [09:21<00:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 687/700 [09:21<00:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 688/700 [09:22<00:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 689/700 [09:23<00:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▊| 690/700 [09:24<00:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▊| 691/700 [09:25<00:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 692/700 [09:26<00:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 693/700 [09:26<00:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 694/700 [09:27<00:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 695/700 [09:28<00:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 696/700 [09:29<00:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|█████████▉| 697/700 [09:30<00:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|█████████▉| 698/700 [09:30<00:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|█████████▉| 699/700 [09:31<00:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|██████████| 700/700 [09:32<00:00,  1.22it/s]100%|██████████| 700/700 [09:32<00:00,  1.22it/s]
tensor(1.5633, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5533, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5657, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5624, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5641, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5572, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5561, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5542, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5614, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5662, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5653, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5597, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5646, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5604, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5589, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5592, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5493, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5601, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5520, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5575, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5508, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5503, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5619, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5481, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5500, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5454, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5518, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5508, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5644, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5477, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5511, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5576, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5575, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5515, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5581, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5548, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5609, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5562, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5543, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5569, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5582, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5587, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5494, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5596, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5629, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5561, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5513, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5599, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5613, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5610, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5501, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5675, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5560, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5633, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5522, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5591, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5568, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5544, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5567, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5565, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5497, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5530, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5590, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5676, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5511, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5506, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5498, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5522, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5486, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5513, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5432, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5531, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5480, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5555, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5569, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5443, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5578, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5493, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5491, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5479, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5545, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5458, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5491, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5533, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5491, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5590, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5498, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5580, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5630, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5490, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5511, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5516, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5459, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5594, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5454, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5506, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5587, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5460, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5548, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5534, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5505, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5604, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5583, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5496, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5551, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5424, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5503, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5520, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5542, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5629, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5579, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5533, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5568, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5555, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5510, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5511, device='cuda:0', grad_fn=<AddBackward0>)
  0%|          | 0/50 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  2%|▏         | 1/50 [00:14<11:33, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  4%|▍         | 2/50 [00:28<11:19, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  6%|▌         | 3/50 [00:42<11:05, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  8%|▊         | 4/50 [00:56<10:51, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 10%|█         | 5/50 [01:10<10:37, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 12%|█▏        | 6/50 [01:24<10:22, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 14%|█▍        | 7/50 [01:39<10:08, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 16%|█▌        | 8/50 [01:53<09:54, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 18%|█▊        | 9/50 [02:07<09:40, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 20%|██        | 10/50 [02:21<09:26, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 22%|██▏       | 11/50 [02:35<09:12, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 24%|██▍       | 12/50 [02:49<08:57, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 26%|██▌       | 13/50 [03:04<08:43, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 28%|██▊       | 14/50 [03:18<08:29, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 30%|███       | 15/50 [03:32<08:15, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 32%|███▏      | 16/50 [03:46<08:00, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 34%|███▍      | 17/50 [04:00<07:46, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 36%|███▌      | 18/50 [04:14<07:32, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 38%|███▊      | 19/50 [04:28<07:18, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 40%|████      | 20/50 [04:43<07:04, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 42%|████▏     | 21/50 [04:57<06:50, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 44%|████▍     | 22/50 [05:11<06:36, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 46%|████▌     | 23/50 [05:25<06:22, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 48%|████▊     | 24/50 [05:39<06:07, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 50%|█████     | 25/50 [05:53<05:53, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 52%|█████▏    | 26/50 [06:07<05:39, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 54%|█████▍    | 27/50 [06:22<05:25, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 56%|█████▌    | 28/50 [06:36<05:11, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 58%|█████▊    | 29/50 [06:50<04:57, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 60%|██████    | 30/50 [07:04<04:43, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 62%|██████▏   | 31/50 [07:18<04:28, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 64%|██████▍   | 32/50 [07:32<04:14, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 66%|██████▌   | 33/50 [07:46<04:00, 14.13s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 68%|██████▊   | 34/50 [08:01<03:46, 14.13s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 70%|███████   | 35/50 [08:15<03:32, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 72%|███████▏  | 36/50 [08:29<03:17, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 74%|███████▍  | 37/50 [08:43<03:03, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 76%|███████▌  | 38/50 [08:57<02:49, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 78%|███████▊  | 39/50 [09:11<02:35, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 80%|████████  | 40/50 [09:25<02:21, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 82%|████████▏ | 41/50 [09:40<02:07, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 84%|████████▍ | 42/50 [09:54<01:53, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 86%|████████▌ | 43/50 [10:08<01:39, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 88%|████████▊ | 44/50 [10:22<01:24, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 90%|█████████ | 45/50 [10:36<01:10, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 92%|█████████▏| 46/50 [10:50<00:56, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 94%|█████████▍| 47/50 [11:04<00:42, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 96%|█████████▌| 48/50 [11:19<00:28, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 98%|█████████▊| 49/50 [11:33<00:14, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
100%|██████████| 50/50 [11:47<00:00, 14.14s/it]100%|██████████| 50/50 [11:47<00:00, 14.15s/it]k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing 
transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/1000 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 1/1000 [00:00<13:23,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 2/1000 [00:01<13:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 3/1000 [00:02<13:28,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 4/1000 [00:03<13:28,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 5/1000 [00:04<13:28,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 6/1000 [00:04<13:28,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 7/1000 [00:05<13:27,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 8/1000 [00:06<13:26,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 9/1000 [00:07<13:26,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 10/1000 [00:08<13:25,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 11/1000 [00:08<13:24,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 12/1000 [00:09<13:23,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|▏         | 13/1000 [00:10<13:23,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|▏         | 14/1000 [00:11<13:22,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 15/1000 [00:12<13:22,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 16/1000 [00:13<13:22,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 17/1000 [00:13<13:21,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 18/1000 [00:14<13:21,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 19/1000 [00:15<13:20,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 20/1000 [00:16<13:19,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 21/1000 [00:17<13:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 22/1000 [00:17<13:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 23/1000 [00:18<13:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 24/1000 [00:19<13:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▎         | 25/1000 [00:20<13:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 26/1000 [00:21<13:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 27/1000 [00:22<13:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 28/1000 [00:22<13:20,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 29/1000 [00:23<13:22,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 30/1000 [00:24<13:23,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 31/1000 [00:25<13:23,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 32/1000 [00:26<13:22,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 33/1000 [00:27<13:21,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 34/1000 [00:27<13:20,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▎         | 35/1000 [00:28<13:20,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▎         | 36/1000 [00:29<13:22,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▎         | 37/1000 [00:30<13:23,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 38/1000 [00:31<13:22,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 39/1000 [00:32<13:21,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 40/1000 [00:32<13:21,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 41/1000 [00:33<13:20,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 42/1000 [00:34<13:20,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 43/1000 [00:35<13:19,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 44/1000 [00:36<13:18,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 45/1000 [00:37<13:18,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▍         | 46/1000 [00:37<13:17,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▍         | 47/1000 [00:38<13:15,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▍         | 48/1000 [00:39<13:14,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▍         | 49/1000 [00:40<13:14,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▌         | 50/1000 [00:41<13:12,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▌         | 51/1000 [00:42<13:10,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▌         | 52/1000 [00:42<13:09,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▌         | 53/1000 [00:43<13:08,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▌         | 54/1000 [00:44<13:06,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 55/1000 [00:45<13:06,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 56/1000 [00:46<13:05,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 57/1000 [00:47<13:04,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 58/1000 [00:47<13:02,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 59/1000 [00:48<13:01,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 60/1000 [00:49<13:00,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 61/1000 [00:50<12:58,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 62/1000 [00:51<12:56,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▋         | 63/1000 [00:51<12:55,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▋         | 64/1000 [00:52<12:53,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▋         | 65/1000 [00:53<12:51,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 66/1000 [00:54<12:50,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 67/1000 [00:55<12:48,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 68/1000 [00:56<12:47,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 69/1000 [00:56<12:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 70/1000 [00:57<12:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 71/1000 [00:58<12:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 72/1000 [00:59<12:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 73/1000 [01:00<12:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 74/1000 [01:01<12:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 75/1000 [01:01<12:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 76/1000 [01:02<12:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 77/1000 [01:03<12:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 78/1000 [01:04<12:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 79/1000 [01:05<12:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 80/1000 [01:05<12:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 81/1000 [01:06<12:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 82/1000 [01:07<12:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 83/1000 [01:08<12:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 84/1000 [01:09<12:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 85/1000 [01:10<12:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▊         | 86/1000 [01:10<12:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▊         | 87/1000 [01:11<12:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 88/1000 [01:12<12:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 89/1000 [01:13<12:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 90/1000 [01:14<12:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 91/1000 [01:14<12:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 92/1000 [01:15<12:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 93/1000 [01:16<12:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 94/1000 [01:17<12:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|▉         | 95/1000 [01:18<12:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|▉         | 96/1000 [01:19<12:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|▉         | 97/1000 [01:19<12:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|▉         | 98/1000 [01:20<12:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|▉         | 99/1000 [01:21<12:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 100/1000 [01:22<12:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 101/1000 [01:23<12:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 102/1000 [01:23<12:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 103/1000 [01:24<12:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 104/1000 [01:25<12:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 105/1000 [01:26<12:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 106/1000 [01:27<12:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 107/1000 [01:28<12:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 108/1000 [01:28<12:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 109/1000 [01:29<12:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 110/1000 [01:30<12:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 111/1000 [01:31<12:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 112/1000 [01:32<12:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█▏        | 113/1000 [01:32<12:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█▏        | 114/1000 [01:33<12:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 115/1000 [01:34<12:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 116/1000 [01:35<12:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 117/1000 [01:36<12:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 118/1000 [01:37<12:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 119/1000 [01:37<11:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 120/1000 [01:38<11:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 121/1000 [01:39<11:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 122/1000 [01:40<11:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 123/1000 [01:41<11:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 124/1000 [01:41<11:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▎        | 125/1000 [01:42<11:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 126/1000 [01:43<11:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 127/1000 [01:44<11:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 128/1000 [01:45<11:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 129/1000 [01:45<11:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 130/1000 [01:46<11:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 131/1000 [01:47<11:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 132/1000 [01:48<11:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 133/1000 [01:49<11:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 134/1000 [01:50<11:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▎        | 135/1000 [01:50<11:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▎        | 136/1000 [01:51<11:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▎        | 137/1000 [01:52<11:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 138/1000 [01:53<11:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 139/1000 [01:54<11:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 140/1000 [01:54<11:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 141/1000 [01:55<11:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 142/1000 [01:56<11:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 143/1000 [01:57<11:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 144/1000 [01:58<11:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 145/1000 [01:59<11:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▍        | 146/1000 [01:59<11:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
tensor(9.2985, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.8493, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.9536, device='cuda:0', grad_fn=<AddBackward0>)
tensor(9.0854, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.5857, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.1565, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.9873, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.7717, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.0648, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.6954, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.8036, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.6316, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.4633, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.5475, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.9426, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.8896, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.7509, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.7513, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.2259, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.7203, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.0610, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.0354, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.9231, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.5463, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.7544, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.3300, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.4716, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.1389, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.9060, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.4627, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.1059, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.0713, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.7422, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.5832, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.7319, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.6644, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.6257, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.9487, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.7928, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.6328, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.8002, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.2646, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.8276, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.9229, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.7635, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.8827, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.9216, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.3845, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.8948, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.7350, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.8587, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.2400, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.2017, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.9822, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.9614, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.7082, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.4123, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.2504, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.9546, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.7245, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.8323, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.7164, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.7646, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4197, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3445, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.5697, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3670, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3296, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.5588, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.7564, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.6438, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4015, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3094, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2419, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2453, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2788, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2463, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3449, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0803, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0102, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1271, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1945, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3979, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1346, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9573, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0270, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9832, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1321, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0234, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0412, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1198, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8645, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9995, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9401, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9493, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8968, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8789, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9408, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0265, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9453, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8987, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8891, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9731, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9759, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8512, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9283, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8939, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8381, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0146, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8293, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8619, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8630, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8933, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8003, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8108, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7350, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7681, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7420, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8702, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7885, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9577, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8890, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0019, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9286, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8020, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8476, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7323, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8388, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8214, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8600, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9531, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7893, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8230, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9062, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7510, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7209, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8473, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6606, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9721, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8061, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8480, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7968, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7729, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6717, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9881, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6733, device='cuda:0', grad_fn=<AddBackward0>)
 15%|█▍        | 147/1000 [02:00<11:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▍        | 148/1000 [02:01<11:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▍        | 149/1000 [02:02<11:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▌        | 150/1000 [02:03<11:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▌        | 151/1000 [02:03<11:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▌        | 152/1000 [02:04<11:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▌        | 153/1000 [02:05<11:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▌        | 154/1000 [02:06<11:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 155/1000 [02:07<11:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 156/1000 [02:08<11:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 157/1000 [02:08<11:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 158/1000 [02:09<11:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 159/1000 [02:10<11:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 160/1000 [02:11<11:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 161/1000 [02:12<11:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 162/1000 [02:12<11:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▋        | 163/1000 [02:13<11:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▋        | 164/1000 [02:14<11:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▋        | 165/1000 [02:15<11:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 166/1000 [02:16<11:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 167/1000 [02:17<11:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 168/1000 [02:17<11:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 169/1000 [02:18<11:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 170/1000 [02:19<11:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 171/1000 [02:20<11:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 172/1000 [02:21<11:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 173/1000 [02:21<11:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 174/1000 [02:22<11:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 175/1000 [02:23<11:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 176/1000 [02:24<11:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 177/1000 [02:25<11:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 178/1000 [02:26<11:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 179/1000 [02:26<11:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 180/1000 [02:27<11:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 181/1000 [02:28<11:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 182/1000 [02:29<11:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 183/1000 [02:30<11:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 184/1000 [02:30<11:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 185/1000 [02:31<11:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▊        | 186/1000 [02:32<11:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▊        | 187/1000 [02:33<11:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 188/1000 [02:34<11:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 189/1000 [02:35<11:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 190/1000 [02:35<11:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 191/1000 [02:36<11:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 192/1000 [02:37<11:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 193/1000 [02:38<10:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 194/1000 [02:39<10:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|█▉        | 195/1000 [02:39<10:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|█▉        | 196/1000 [02:40<10:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|█▉        | 197/1000 [02:41<10:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|█▉        | 198/1000 [02:42<10:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|█▉        | 199/1000 [02:43<10:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 200/1000 [02:44<10:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 201/1000 [02:44<10:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 202/1000 [02:45<10:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 203/1000 [02:46<10:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 204/1000 [02:47<10:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 205/1000 [02:48<10:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 206/1000 [02:48<10:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 207/1000 [02:49<10:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 208/1000 [02:50<10:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 209/1000 [02:51<10:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 210/1000 [02:52<10:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 211/1000 [02:53<10:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 212/1000 [02:53<10:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██▏       | 213/1000 [02:54<10:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██▏       | 214/1000 [02:55<10:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 215/1000 [02:56<10:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 216/1000 [02:57<10:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 217/1000 [02:57<10:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 218/1000 [02:58<10:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 219/1000 [02:59<10:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 220/1000 [03:00<10:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 221/1000 [03:01<10:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 222/1000 [03:02<10:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 223/1000 [03:02<10:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 224/1000 [03:03<10:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▎       | 225/1000 [03:04<10:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 226/1000 [03:05<10:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 227/1000 [03:06<10:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 228/1000 [03:06<10:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 229/1000 [03:07<10:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 230/1000 [03:08<10:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 231/1000 [03:09<10:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 232/1000 [03:10<10:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 233/1000 [03:11<10:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 234/1000 [03:11<10:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▎       | 235/1000 [03:12<10:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▎       | 236/1000 [03:13<10:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▎       | 237/1000 [03:14<10:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 238/1000 [03:15<10:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 239/1000 [03:15<10:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 240/1000 [03:16<10:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 241/1000 [03:17<10:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 242/1000 [03:18<10:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 243/1000 [03:19<10:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 244/1000 [03:19<10:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 245/1000 [03:20<10:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▍       | 246/1000 [03:21<10:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▍       | 247/1000 [03:22<10:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▍       | 248/1000 [03:23<10:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▍       | 249/1000 [03:24<10:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▌       | 250/1000 [03:24<10:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▌       | 251/1000 [03:25<10:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▌       | 252/1000 [03:26<10:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▌       | 253/1000 [03:27<10:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▌       | 254/1000 [03:28<10:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 255/1000 [03:28<10:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 256/1000 [03:29<10:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 257/1000 [03:30<10:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 258/1000 [03:31<10:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 259/1000 [03:32<10:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 260/1000 [03:33<10:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 261/1000 [03:33<10:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 262/1000 [03:34<10:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▋       | 263/1000 [03:35<10:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▋       | 264/1000 [03:36<10:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▋       | 265/1000 [03:37<10:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 266/1000 [03:37<10:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 267/1000 [03:38<09:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 268/1000 [03:39<09:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 269/1000 [03:40<09:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 270/1000 [03:41<09:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 271/1000 [03:42<09:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 272/1000 [03:42<09:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 273/1000 [03:43<09:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 274/1000 [03:44<09:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 275/1000 [03:45<09:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 276/1000 [03:46<09:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 277/1000 [03:46<09:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 278/1000 [03:47<09:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 279/1000 [03:48<09:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 280/1000 [03:49<09:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 281/1000 [03:50<09:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 282/1000 [03:51<09:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 283/1000 [03:51<09:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 284/1000 [03:52<09:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 285/1000 [03:53<09:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▊       | 286/1000 [03:54<09:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▊       | 287/1000 [03:55<09:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 288/1000 [03:55<09:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 289/1000 [03:56<09:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 290/1000 [03:57<09:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 291/1000 [03:58<09:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 292/1000 [03:59<09:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
tensor(1.7133, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9149, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7267, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7527, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6839, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7446, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7360, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6792, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7478, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7347, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6446, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7759, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7301, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7593, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7198, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6893, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6940, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7610, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7581, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7185, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7145, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6598, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7043, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6344, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6415, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6444, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6959, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7259, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6358, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6740, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7385, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7979, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6298, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6318, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6367, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6884, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6924, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6289, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7180, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6584, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6841, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6527, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6680, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7432, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7382, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7746, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7040, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6382, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7626, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6358, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6986, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6627, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6771, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7168, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6902, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6089, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6467, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7218, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6429, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6969, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6955, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7248, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6367, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6271, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6478, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6451, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6151, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5918, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6086, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7014, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6267, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6380, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6451, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6092, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6364, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6753, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6999, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6241, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6046, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6443, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6327, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6033, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.7448, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6693, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6039, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6411, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6025, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6370, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6598, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5998, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6713, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6755, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6924, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6390, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6737, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6690, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6930, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6509, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6129, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6020, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6448, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6249, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6510, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6402, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6345, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6165, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6348, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6287, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5854, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6241, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5984, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5930, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6145, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6075, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6193, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6140, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6163, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5941, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5806, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5942, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6477, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5835, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6036, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6173, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6335, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6506, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6354, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6208, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6078, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6229, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6265, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5908, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6278, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5991, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6317, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6183, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5888, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6441, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6020, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5993, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5955, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6800, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6306, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6589, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6463, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6048, device='cuda:0', grad_fn=<AddBackward0>)
 29%|██▉       | 293/1000 [04:00<09:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 294/1000 [04:00<09:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|██▉       | 295/1000 [04:01<09:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|██▉       | 296/1000 [04:02<09:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|██▉       | 297/1000 [04:03<09:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|██▉       | 298/1000 [04:04<09:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|██▉       | 299/1000 [04:04<09:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 300/1000 [04:05<09:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 301/1000 [04:06<09:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 302/1000 [04:07<09:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 303/1000 [04:08<09:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 304/1000 [04:09<09:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 305/1000 [04:09<09:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 306/1000 [04:10<09:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 307/1000 [04:11<09:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 308/1000 [04:12<09:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 309/1000 [04:13<09:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 310/1000 [04:13<09:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 311/1000 [04:14<09:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 312/1000 [04:15<09:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███▏      | 313/1000 [04:16<09:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███▏      | 314/1000 [04:17<09:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 315/1000 [04:18<09:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 316/1000 [04:18<09:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 317/1000 [04:19<09:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 318/1000 [04:20<09:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 319/1000 [04:21<09:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 320/1000 [04:22<09:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 321/1000 [04:22<09:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 322/1000 [04:23<09:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 323/1000 [04:24<09:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 324/1000 [04:25<09:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▎      | 325/1000 [04:26<09:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 326/1000 [04:27<09:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 327/1000 [04:27<09:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 328/1000 [04:28<09:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 329/1000 [04:29<09:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 330/1000 [04:30<09:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 331/1000 [04:31<09:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 332/1000 [04:31<09:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 333/1000 [04:32<09:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 334/1000 [04:33<09:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▎      | 335/1000 [04:34<09:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▎      | 336/1000 [04:35<09:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▎      | 337/1000 [04:36<09:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 338/1000 [04:36<09:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 339/1000 [04:37<09:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 340/1000 [04:38<08:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 341/1000 [04:39<08:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 342/1000 [04:40<08:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 343/1000 [04:40<08:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 344/1000 [04:41<08:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 345/1000 [04:42<08:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▍      | 346/1000 [04:43<08:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▍      | 347/1000 [04:44<08:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▍      | 348/1000 [04:45<08:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▍      | 349/1000 [04:45<08:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▌      | 350/1000 [04:46<08:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▌      | 351/1000 [04:47<08:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▌      | 352/1000 [04:48<08:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▌      | 353/1000 [04:49<08:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▌      | 354/1000 [04:49<08:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 355/1000 [04:50<08:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 356/1000 [04:51<08:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 357/1000 [04:52<08:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 358/1000 [04:53<08:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 359/1000 [04:54<08:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 360/1000 [04:54<08:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 361/1000 [04:55<08:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 362/1000 [04:56<08:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▋      | 363/1000 [04:57<08:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▋      | 364/1000 [04:58<08:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▋      | 365/1000 [04:58<08:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 366/1000 [04:59<08:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 367/1000 [05:00<08:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 368/1000 [05:01<08:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 369/1000 [05:02<08:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 370/1000 [05:03<08:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 371/1000 [05:03<08:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 372/1000 [05:04<08:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 373/1000 [05:05<08:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 374/1000 [05:06<08:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 375/1000 [05:07<08:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 376/1000 [05:07<08:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 377/1000 [05:08<08:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 378/1000 [05:09<08:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 379/1000 [05:10<08:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 380/1000 [05:11<08:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 381/1000 [05:12<08:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 382/1000 [05:12<08:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 383/1000 [05:13<08:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 384/1000 [05:14<08:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 385/1000 [05:15<08:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▊      | 386/1000 [05:16<08:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▊      | 387/1000 [05:16<08:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 388/1000 [05:17<08:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 389/1000 [05:18<08:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 390/1000 [05:19<08:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 391/1000 [05:20<08:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 392/1000 [05:21<08:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 393/1000 [05:21<08:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 394/1000 [05:22<08:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|███▉      | 395/1000 [05:23<08:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|███▉      | 396/1000 [05:24<08:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|███▉      | 397/1000 [05:25<08:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|███▉      | 398/1000 [05:25<08:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|███▉      | 399/1000 [05:26<08:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 400/1000 [05:27<08:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 401/1000 [05:28<08:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 402/1000 [05:29<08:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 403/1000 [05:30<08:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 404/1000 [05:30<08:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 405/1000 [05:31<08:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 406/1000 [05:32<08:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 407/1000 [05:33<08:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 408/1000 [05:34<08:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 409/1000 [05:35<08:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 410/1000 [05:35<08:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 411/1000 [05:36<08:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 412/1000 [05:37<08:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████▏     | 413/1000 [05:38<08:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████▏     | 414/1000 [05:39<07:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 415/1000 [05:39<07:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 416/1000 [05:40<07:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 417/1000 [05:41<07:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 418/1000 [05:42<07:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 419/1000 [05:43<07:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 420/1000 [05:44<07:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 421/1000 [05:44<07:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 422/1000 [05:45<07:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 423/1000 [05:46<07:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 424/1000 [05:47<07:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▎     | 425/1000 [05:48<07:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 426/1000 [05:48<07:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 427/1000 [05:49<07:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 428/1000 [05:50<07:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 429/1000 [05:51<07:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 430/1000 [05:52<07:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 431/1000 [05:52<07:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 432/1000 [05:53<07:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 433/1000 [05:54<07:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 434/1000 [05:55<07:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▎     | 435/1000 [05:56<07:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▎     | 436/1000 [05:57<07:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▎     | 437/1000 [05:57<07:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 438/1000 [05:58<07:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
tensor(1.5997, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6258, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6020, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6512, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6135, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6339, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6263, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6162, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5926, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5937, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5973, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6025, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5994, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6003, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5771, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6020, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5928, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5969, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5863, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5708, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6035, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6214, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6022, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6033, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6089, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6165, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5910, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5937, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5928, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6072, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5828, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6305, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6011, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5997, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5998, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5731, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6099, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6126, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6059, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6274, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5749, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5854, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5961, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5987, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6191, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5986, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5947, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5856, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5944, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6171, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6008, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5757, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5853, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5975, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6032, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6271, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6340, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5726, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5547, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5797, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5777, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5757, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5860, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5779, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5890, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5741, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5645, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5727, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6032, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5897, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5686, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5987, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5915, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5818, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5840, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5920, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5921, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5944, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5895, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5728, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6034, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5665, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5946, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5949, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5677, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5712, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6127, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5874, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5746, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5827, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6023, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6035, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5925, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5998, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5915, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5899, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5885, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5874, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5909, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5918, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6063, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6053, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5912, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5964, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5841, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5731, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5964, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5796, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5713, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5740, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5699, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5776, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5833, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5770, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5693, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5734, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5733, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5788, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5695, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5587, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5738, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5840, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5752, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5942, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6061, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5799, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5739, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5786, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5730, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5934, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5857, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5775, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5885, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5811, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5736, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5674, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5715, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6023, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5747, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5848, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5709, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5638, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5646, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5890, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5666, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5817, device='cuda:0', grad_fn=<AddBackward0>)
 44%|████▍     | 439/1000 [05:59<07:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 440/1000 [06:00<07:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 441/1000 [06:01<07:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 442/1000 [06:01<07:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 443/1000 [06:02<07:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 444/1000 [06:03<07:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 445/1000 [06:04<07:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▍     | 446/1000 [06:05<07:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▍     | 447/1000 [06:06<07:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▍     | 448/1000 [06:06<07:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▍     | 449/1000 [06:07<07:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▌     | 450/1000 [06:08<07:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▌     | 451/1000 [06:09<07:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▌     | 452/1000 [06:10<07:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▌     | 453/1000 [06:10<07:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▌     | 454/1000 [06:11<07:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 455/1000 [06:12<07:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 456/1000 [06:13<07:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 457/1000 [06:14<07:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 458/1000 [06:15<07:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 459/1000 [06:15<07:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 460/1000 [06:16<07:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 461/1000 [06:17<07:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 462/1000 [06:18<07:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▋     | 463/1000 [06:19<07:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▋     | 464/1000 [06:19<07:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▋     | 465/1000 [06:20<07:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 466/1000 [06:21<07:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 467/1000 [06:22<07:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 468/1000 [06:23<07:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 469/1000 [06:24<07:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 470/1000 [06:24<07:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 471/1000 [06:25<07:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 472/1000 [06:26<07:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 473/1000 [06:27<07:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 474/1000 [06:28<07:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 475/1000 [06:28<07:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 476/1000 [06:29<07:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 477/1000 [06:30<07:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 478/1000 [06:31<07:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 479/1000 [06:32<07:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 480/1000 [06:33<07:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 481/1000 [06:33<07:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 482/1000 [06:34<07:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 483/1000 [06:35<07:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 484/1000 [06:36<07:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 485/1000 [06:37<07:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▊     | 486/1000 [06:37<07:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▊     | 487/1000 [06:38<06:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 488/1000 [06:39<06:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 489/1000 [06:40<06:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 490/1000 [06:41<06:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 491/1000 [06:42<06:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 492/1000 [06:42<06:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 493/1000 [06:43<06:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 494/1000 [06:44<06:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|████▉     | 495/1000 [06:45<06:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|████▉     | 496/1000 [06:46<06:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|████▉     | 497/1000 [06:46<06:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|████▉     | 498/1000 [06:47<06:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|████▉     | 499/1000 [06:48<06:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 500/1000 [06:49<06:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 501/1000 [06:50<06:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 502/1000 [06:51<06:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 503/1000 [06:51<06:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 504/1000 [06:52<06:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 505/1000 [06:53<06:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 506/1000 [06:54<06:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 507/1000 [06:55<06:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 508/1000 [06:55<06:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 509/1000 [06:56<06:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 510/1000 [06:57<06:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 511/1000 [06:58<06:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 512/1000 [06:59<06:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████▏    | 513/1000 [07:00<06:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████▏    | 514/1000 [07:00<06:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 515/1000 [07:01<06:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 516/1000 [07:02<06:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 517/1000 [07:03<06:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 518/1000 [07:04<06:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 519/1000 [07:04<06:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 520/1000 [07:05<06:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 521/1000 [07:06<06:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 522/1000 [07:07<06:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 523/1000 [07:08<06:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 524/1000 [07:08<06:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▎    | 525/1000 [07:09<06:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 526/1000 [07:10<06:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 527/1000 [07:11<06:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 528/1000 [07:12<06:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 529/1000 [07:13<06:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 530/1000 [07:13<06:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 531/1000 [07:14<06:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 532/1000 [07:15<06:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 533/1000 [07:16<06:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 534/1000 [07:17<06:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▎    | 535/1000 [07:17<06:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▎    | 536/1000 [07:18<06:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▎    | 537/1000 [07:19<06:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 538/1000 [07:20<06:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 539/1000 [07:21<06:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 540/1000 [07:22<06:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 541/1000 [07:22<06:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 542/1000 [07:23<06:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 543/1000 [07:24<06:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 544/1000 [07:25<06:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▍    | 545/1000 [07:26<06:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▍    | 546/1000 [07:26<06:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▍    | 547/1000 [07:27<06:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▍    | 548/1000 [07:28<06:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▍    | 549/1000 [07:29<06:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▌    | 550/1000 [07:30<06:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▌    | 551/1000 [07:31<06:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▌    | 552/1000 [07:31<06:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▌    | 553/1000 [07:32<06:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▌    | 554/1000 [07:33<06:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 555/1000 [07:34<06:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 556/1000 [07:35<06:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 557/1000 [07:35<06:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 558/1000 [07:36<06:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 559/1000 [07:37<06:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 560/1000 [07:38<05:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 561/1000 [07:39<05:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 562/1000 [07:40<05:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▋    | 563/1000 [07:40<05:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▋    | 564/1000 [07:41<05:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▋    | 565/1000 [07:42<05:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 566/1000 [07:43<05:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 567/1000 [07:44<05:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 568/1000 [07:44<05:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 569/1000 [07:45<05:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 570/1000 [07:46<05:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 571/1000 [07:47<05:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 572/1000 [07:48<05:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 573/1000 [07:49<05:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 574/1000 [07:49<05:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▊    | 575/1000 [07:50<05:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 576/1000 [07:51<05:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 577/1000 [07:52<05:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 578/1000 [07:53<05:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 579/1000 [07:53<05:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 580/1000 [07:54<05:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 581/1000 [07:55<05:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 582/1000 [07:56<05:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 583/1000 [07:57<05:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 584/1000 [07:58<05:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
tensor(1.5951, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5989, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5806, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5764, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5765, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5861, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5837, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5871, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5929, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5709, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5870, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.6049, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5520, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5697, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5632, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5780, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5670, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5695, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5677, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5764, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5627, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5720, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5608, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5615, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5686, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5648, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5724, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5668, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5708, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5774, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5678, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5817, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5865, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5667, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5668, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5735, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5758, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5664, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5824, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5586, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5701, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5799, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5719, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5736, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5855, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5817, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5702, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5723, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5762, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5845, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5736, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5704, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5777, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5796, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5802, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5681, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5691, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5801, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5662, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5742, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5768, device='cuda:0', grad_fn=<AddBackward0>)
500
tensor(1.5621, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5592, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5687, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5632, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5608, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5580, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5535, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5581, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5624, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5704, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5614, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5856, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5588, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5652, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5680, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5653, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5672, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5631, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5670, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5599, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5623, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5767, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5681, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5694, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5586, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5866, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5657, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5648, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5643, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5640, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5689, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5672, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5673, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5629, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5620, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5675, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5790, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5630, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5657, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5724, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5688, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5678, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5724, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5786, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5753, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5696, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5648, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5670, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5649, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5712, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5686, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5629, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5534, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5485, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5618, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5482, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5623, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5682, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5580, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5625, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5724, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5596, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5640, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5595, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5607, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5652, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5643, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5518, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5634, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5568, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5681, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5641, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5586, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5653, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5706, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5562, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5543, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5621, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5569, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5570, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5580, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5499, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5650, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5659, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5615, device='cuda:0', grad_fn=<AddBackward0>)
 58%|█████▊    | 585/1000 [07:58<05:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▊    | 586/1000 [07:59<05:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▊    | 587/1000 [08:00<05:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 588/1000 [08:01<05:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 589/1000 [08:02<05:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 590/1000 [08:02<05:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 591/1000 [08:03<05:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 592/1000 [08:04<05:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 593/1000 [08:05<05:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 594/1000 [08:06<05:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|█████▉    | 595/1000 [08:07<05:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|█████▉    | 596/1000 [08:07<05:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|█████▉    | 597/1000 [08:08<05:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|█████▉    | 598/1000 [08:09<05:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|█████▉    | 599/1000 [08:10<05:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 600/1000 [08:11<05:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 601/1000 [08:11<05:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 602/1000 [08:12<05:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 603/1000 [08:13<05:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 604/1000 [08:14<05:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 605/1000 [08:15<05:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 606/1000 [08:16<05:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 607/1000 [08:16<05:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 608/1000 [08:17<05:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 609/1000 [08:18<05:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 610/1000 [08:19<05:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 611/1000 [08:20<05:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 612/1000 [08:20<05:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████▏   | 613/1000 [08:21<05:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████▏   | 614/1000 [08:22<05:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 615/1000 [08:23<05:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 616/1000 [08:24<05:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 617/1000 [08:25<05:15,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 618/1000 [08:25<05:15,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 619/1000 [08:26<05:15,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 620/1000 [08:27<05:15,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 621/1000 [08:28<05:13,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 622/1000 [08:29<05:11,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 623/1000 [08:29<05:10,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 624/1000 [08:30<05:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▎   | 625/1000 [08:31<05:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 626/1000 [08:32<05:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 627/1000 [08:33<05:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 628/1000 [08:34<05:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 629/1000 [08:34<05:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 630/1000 [08:35<05:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 631/1000 [08:36<05:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 632/1000 [08:37<05:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 633/1000 [08:38<05:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 634/1000 [08:38<04:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▎   | 635/1000 [08:39<04:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▎   | 636/1000 [08:40<04:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▎   | 637/1000 [08:41<04:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 638/1000 [08:42<04:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 639/1000 [08:43<04:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 640/1000 [08:43<04:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 641/1000 [08:44<04:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 642/1000 [08:45<04:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 643/1000 [08:46<04:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 644/1000 [08:47<04:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 645/1000 [08:47<04:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▍   | 646/1000 [08:48<04:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▍   | 647/1000 [08:49<04:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▍   | 648/1000 [08:50<04:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▍   | 649/1000 [08:51<04:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▌   | 650/1000 [08:52<04:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▌   | 651/1000 [08:52<04:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▌   | 652/1000 [08:53<04:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▌   | 653/1000 [08:54<04:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▌   | 654/1000 [08:55<04:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 655/1000 [08:56<04:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 656/1000 [08:56<04:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 657/1000 [08:57<04:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 658/1000 [08:58<04:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 659/1000 [08:59<04:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 660/1000 [09:00<04:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 661/1000 [09:01<04:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 662/1000 [09:01<04:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▋   | 663/1000 [09:02<04:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▋   | 664/1000 [09:03<04:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▋   | 665/1000 [09:04<04:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 666/1000 [09:05<04:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 667/1000 [09:05<04:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 668/1000 [09:06<04:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 669/1000 [09:07<04:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 670/1000 [09:08<04:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 671/1000 [09:09<04:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 672/1000 [09:10<04:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 673/1000 [09:10<04:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 674/1000 [09:11<04:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 675/1000 [09:12<04:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 676/1000 [09:13<04:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 677/1000 [09:14<04:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 678/1000 [09:14<04:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 679/1000 [09:15<04:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 680/1000 [09:16<04:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 681/1000 [09:17<04:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 682/1000 [09:18<04:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 683/1000 [09:19<04:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 684/1000 [09:19<04:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 685/1000 [09:20<04:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▊   | 686/1000 [09:21<04:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▊   | 687/1000 [09:22<04:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 688/1000 [09:23<04:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 689/1000 [09:23<04:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 690/1000 [09:24<04:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 691/1000 [09:25<04:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 692/1000 [09:26<04:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 693/1000 [09:27<04:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 694/1000 [09:28<04:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|██████▉   | 695/1000 [09:28<04:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|██████▉   | 696/1000 [09:29<04:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|██████▉   | 697/1000 [09:30<04:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|██████▉   | 698/1000 [09:31<04:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|██████▉   | 699/1000 [09:32<04:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 700/1000 [09:32<04:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 701/1000 [09:33<04:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 702/1000 [09:34<04:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 703/1000 [09:35<04:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 704/1000 [09:36<04:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 705/1000 [09:37<04:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 706/1000 [09:37<04:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 707/1000 [09:38<03:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 708/1000 [09:39<03:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 709/1000 [09:40<03:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 710/1000 [09:41<03:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 711/1000 [09:41<03:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 712/1000 [09:42<03:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████▏  | 713/1000 [09:43<03:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████▏  | 714/1000 [09:44<03:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 715/1000 [09:45<03:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 716/1000 [09:46<03:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 717/1000 [09:46<03:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 718/1000 [09:47<03:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 719/1000 [09:48<03:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 720/1000 [09:49<03:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 721/1000 [09:50<03:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 722/1000 [09:50<03:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 723/1000 [09:51<03:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 724/1000 [09:52<03:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▎  | 725/1000 [09:53<03:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 726/1000 [09:54<03:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 727/1000 [09:54<03:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 728/1000 [09:55<03:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 729/1000 [09:56<03:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 730/1000 [09:57<03:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
tensor(1.5606, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5553, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5638, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5722, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5657, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5603, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5718, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5630, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5657, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5715, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5602, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5645, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5624, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5703, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5654, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5612, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5482, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5571, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5460, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5639, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5539, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5508, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5548, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5526, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5472, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5535, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5540, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5625, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5590, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5549, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5648, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5545, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5600, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5583, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5597, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5609, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5619, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5500, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5628, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5639, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5565, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5721, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5601, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5524, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5607, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5614, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5555, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5593, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5571, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5625, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5579, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5578, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5516, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5584, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5615, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5648, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5582, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5654, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5570, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5690, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5615, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5626, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5618, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5676, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5727, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5726, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5477, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5508, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5425, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5520, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5520, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5544, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5556, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5615, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5573, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5422, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5520, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5593, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5600, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5568, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5489, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5509, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5543, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5488, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5521, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5618, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5495, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5628, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5511, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5578, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5511, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5570, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5641, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5508, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5530, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5591, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5543, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5449, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5499, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5529, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5628, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5530, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5613, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5654, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5576, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5623, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5575, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5559, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5512, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5634, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5645, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5647, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5516, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5620, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5569, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5638, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5440, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5471, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5513, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5468, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5396, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5496, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5485, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5556, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5419, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5505, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5499, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5556, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5457, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5524, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5479, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5531, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5557, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5568, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5440, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5499, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5510, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5429, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5562, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5494, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5574, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5482, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5571, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5534, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5513, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5572, device='cuda:0', grad_fn=<AddBackward0>)
 73%|███████▎  | 731/1000 [09:58<03:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 732/1000 [09:59<03:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 733/1000 [09:59<03:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 734/1000 [10:00<03:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▎  | 735/1000 [10:01<03:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▎  | 736/1000 [10:02<03:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▎  | 737/1000 [10:03<03:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 738/1000 [10:03<03:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 739/1000 [10:04<03:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 740/1000 [10:05<03:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 741/1000 [10:06<03:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 742/1000 [10:07<03:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 743/1000 [10:08<03:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 744/1000 [10:08<03:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 745/1000 [10:09<03:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▍  | 746/1000 [10:10<03:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▍  | 747/1000 [10:11<03:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▍  | 748/1000 [10:12<03:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▍  | 749/1000 [10:12<03:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▌  | 750/1000 [10:13<03:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▌  | 751/1000 [10:14<03:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▌  | 752/1000 [10:15<03:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▌  | 753/1000 [10:16<03:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▌  | 754/1000 [10:17<03:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 755/1000 [10:17<03:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 756/1000 [10:18<03:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 757/1000 [10:19<03:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 758/1000 [10:20<03:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 759/1000 [10:21<03:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 760/1000 [10:21<03:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 761/1000 [10:22<03:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 762/1000 [10:23<03:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▋  | 763/1000 [10:24<03:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▋  | 764/1000 [10:25<03:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▋  | 765/1000 [10:26<03:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 766/1000 [10:26<03:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 767/1000 [10:27<03:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 768/1000 [10:28<03:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 769/1000 [10:29<03:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 770/1000 [10:30<03:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 771/1000 [10:30<03:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 772/1000 [10:31<03:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 773/1000 [10:32<03:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 774/1000 [10:33<03:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 775/1000 [10:34<03:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 776/1000 [10:35<03:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 777/1000 [10:35<03:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 778/1000 [10:36<03:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 779/1000 [10:37<03:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 780/1000 [10:38<02:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 781/1000 [10:39<02:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 782/1000 [10:39<02:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 783/1000 [10:40<02:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 784/1000 [10:41<02:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 785/1000 [10:42<02:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▊  | 786/1000 [10:43<02:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▊  | 787/1000 [10:44<02:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 788/1000 [10:44<02:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 789/1000 [10:45<02:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 790/1000 [10:46<02:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 791/1000 [10:47<02:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 792/1000 [10:48<02:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 793/1000 [10:48<02:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 794/1000 [10:49<02:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|███████▉  | 795/1000 [10:50<02:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|███████▉  | 796/1000 [10:51<02:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|███████▉  | 797/1000 [10:52<02:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|███████▉  | 798/1000 [10:53<02:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|███████▉  | 799/1000 [10:53<02:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 800/1000 [10:54<02:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 801/1000 [10:55<02:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 802/1000 [10:56<02:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 803/1000 [10:57<02:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 804/1000 [10:57<02:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 805/1000 [10:58<02:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 806/1000 [10:59<02:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 807/1000 [11:00<02:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 808/1000 [11:01<02:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 809/1000 [11:02<02:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 810/1000 [11:02<02:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 811/1000 [11:03<02:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 812/1000 [11:04<02:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████▏ | 813/1000 [11:05<02:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████▏ | 814/1000 [11:06<02:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 815/1000 [11:06<02:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 816/1000 [11:07<02:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 817/1000 [11:08<02:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 818/1000 [11:09<02:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 819/1000 [11:10<02:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 820/1000 [11:11<02:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 821/1000 [11:11<02:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 822/1000 [11:12<02:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 823/1000 [11:13<02:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 824/1000 [11:14<02:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▎ | 825/1000 [11:15<02:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 826/1000 [11:15<02:23,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 827/1000 [11:16<02:23,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 828/1000 [11:17<02:22,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 829/1000 [11:18<02:21,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 830/1000 [11:19<02:20,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 831/1000 [11:20<02:19,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 832/1000 [11:20<02:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 833/1000 [11:21<02:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 834/1000 [11:22<02:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▎ | 835/1000 [11:23<02:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▎ | 836/1000 [11:24<02:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▎ | 837/1000 [11:24<02:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 838/1000 [11:25<02:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 839/1000 [11:26<02:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 840/1000 [11:27<02:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 841/1000 [11:28<02:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 842/1000 [11:29<02:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 843/1000 [11:29<02:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 844/1000 [11:30<02:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 845/1000 [11:31<02:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▍ | 846/1000 [11:32<02:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▍ | 847/1000 [11:33<02:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▍ | 848/1000 [11:34<02:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▍ | 849/1000 [11:34<02:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▌ | 850/1000 [11:35<02:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▌ | 851/1000 [11:36<02:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▌ | 852/1000 [11:37<02:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▌ | 853/1000 [11:38<02:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▌ | 854/1000 [11:38<01:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 855/1000 [11:39<01:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 856/1000 [11:40<01:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 857/1000 [11:41<01:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 858/1000 [11:42<01:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 859/1000 [11:43<01:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 860/1000 [11:43<01:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 861/1000 [11:44<01:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 862/1000 [11:45<01:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▋ | 863/1000 [11:46<01:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▋ | 864/1000 [11:47<01:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▋ | 865/1000 [11:47<01:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 866/1000 [11:48<01:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 867/1000 [11:49<01:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 868/1000 [11:50<01:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 869/1000 [11:51<01:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 870/1000 [11:52<01:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 871/1000 [11:52<01:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 872/1000 [11:53<01:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 873/1000 [11:54<01:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 874/1000 [11:55<01:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 875/1000 [11:56<01:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 876/1000 [11:56<01:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
tensor(1.5497, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5526, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5570, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5525, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5520, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5534, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5547, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5568, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5544, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5548, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5552, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5543, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5517, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5541, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5514, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5572, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5486, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5475, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5625, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5536, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5470, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5542, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5451, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5502, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5544, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5462, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5477, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5492, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5486, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5445, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5506, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5460, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5401, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5540, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5475, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5485, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5447, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5456, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5483, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5520, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5458, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5496, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5507, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5413, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5442, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5575, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5504, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5491, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5642, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5454, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5514, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5532, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5565, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5501, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5539, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5505, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5566, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5497, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5461, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5574, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5592, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5597, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5463, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5496, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5514, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5491, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5542, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5561, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5529, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5508, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5458, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5444, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5466, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5413, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5471, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5446, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5468, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5477, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5475, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5477, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5460, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5459, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5482, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5468, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5463, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5499, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5405, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5441, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5489, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5481, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5483, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5468, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5485, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5412, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5464, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5426, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5543, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5485, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5550, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5537, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5517, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5463, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5493, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5558, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5539, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5540, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5515, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5468, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5529, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5512, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5472, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5432, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5524, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5535, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5483, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5390, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5506, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5515, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5482, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5529, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5386, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5480, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5495, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5386, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5476, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5442, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5429, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5421, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5461, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5414, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5444, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5422, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5402, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5449, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5458, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5462, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5452, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5487, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5454, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5461, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5485, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5476, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5417, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5474, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5464, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5452, device='cuda:0', grad_fn=<AddBackward0>)
 88%|████████▊ | 877/1000 [11:57<01:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 878/1000 [11:58<01:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 879/1000 [11:59<01:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 880/1000 [12:00<01:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 881/1000 [12:01<01:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 882/1000 [12:01<01:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 883/1000 [12:02<01:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 884/1000 [12:03<01:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 885/1000 [12:04<01:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▊ | 886/1000 [12:05<01:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▊ | 887/1000 [12:05<01:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 888/1000 [12:06<01:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 889/1000 [12:07<01:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 890/1000 [12:08<01:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 891/1000 [12:09<01:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 892/1000 [12:10<01:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 893/1000 [12:10<01:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 894/1000 [12:11<01:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|████████▉ | 895/1000 [12:12<01:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|████████▉ | 896/1000 [12:13<01:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|████████▉ | 897/1000 [12:14<01:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|████████▉ | 898/1000 [12:14<01:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|████████▉ | 899/1000 [12:15<01:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 900/1000 [12:16<01:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 901/1000 [12:17<01:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 902/1000 [12:18<01:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 903/1000 [12:19<01:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 904/1000 [12:19<01:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 905/1000 [12:20<01:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 906/1000 [12:21<01:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 907/1000 [12:22<01:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 908/1000 [12:23<01:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 909/1000 [12:23<01:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 910/1000 [12:24<01:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 911/1000 [12:25<01:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 912/1000 [12:26<01:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████▏| 913/1000 [12:27<01:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████▏| 914/1000 [12:28<01:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 915/1000 [12:28<01:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 916/1000 [12:29<01:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 917/1000 [12:30<01:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 918/1000 [12:31<01:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 919/1000 [12:32<01:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 920/1000 [12:32<01:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 921/1000 [12:33<01:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 922/1000 [12:34<01:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 923/1000 [12:35<01:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 924/1000 [12:36<01:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▎| 925/1000 [12:37<01:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 926/1000 [12:37<01:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 927/1000 [12:38<00:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 928/1000 [12:39<00:59,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 929/1000 [12:40<00:58,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 930/1000 [12:41<00:57,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 931/1000 [12:41<00:56,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 932/1000 [12:42<00:55,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 933/1000 [12:43<00:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 934/1000 [12:44<00:54,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▎| 935/1000 [12:45<00:53,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▎| 936/1000 [12:46<00:52,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▎| 937/1000 [12:46<00:51,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 938/1000 [12:47<00:50,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 939/1000 [12:48<00:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 940/1000 [12:49<00:49,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 941/1000 [12:50<00:48,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 942/1000 [12:50<00:47,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 943/1000 [12:51<00:46,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 944/1000 [12:52<00:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 945/1000 [12:53<00:45,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▍| 946/1000 [12:54<00:44,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▍| 947/1000 [12:55<00:43,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▍| 948/1000 [12:55<00:42,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▍| 949/1000 [12:56<00:41,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▌| 950/1000 [12:57<00:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▌| 951/1000 [12:58<00:40,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▌| 952/1000 [12:59<00:39,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▌| 953/1000 [12:59<00:38,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▌| 954/1000 [13:00<00:37,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 955/1000 [13:01<00:36,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 956/1000 [13:02<00:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 957/1000 [13:03<00:35,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 958/1000 [13:04<00:34,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 959/1000 [13:04<00:33,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 960/1000 [13:05<00:32,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 961/1000 [13:06<00:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 962/1000 [13:07<00:31,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▋| 963/1000 [13:08<00:30,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▋| 964/1000 [13:08<00:29,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▋| 965/1000 [13:09<00:28,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 966/1000 [13:10<00:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 967/1000 [13:11<00:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 968/1000 [13:12<00:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 969/1000 [13:13<00:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 970/1000 [13:13<00:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 971/1000 [13:14<00:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 972/1000 [13:15<00:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 973/1000 [13:16<00:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 974/1000 [13:17<00:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 975/1000 [13:17<00:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 976/1000 [13:18<00:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 977/1000 [13:19<00:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 978/1000 [13:20<00:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 979/1000 [13:21<00:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 980/1000 [13:22<00:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 981/1000 [13:22<00:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 982/1000 [13:23<00:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 983/1000 [13:24<00:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 984/1000 [13:25<00:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 985/1000 [13:26<00:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▊| 986/1000 [13:27<00:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▊| 987/1000 [13:27<00:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 988/1000 [13:28<00:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 989/1000 [13:29<00:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 990/1000 [13:30<00:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 991/1000 [13:31<00:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 992/1000 [13:31<00:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 993/1000 [13:32<00:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 994/1000 [13:33<00:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|█████████▉| 995/1000 [13:34<00:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|█████████▉| 996/1000 [13:35<00:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|█████████▉| 997/1000 [13:36<00:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|█████████▉| 998/1000 [13:36<00:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|█████████▉| 999/1000 [13:37<00:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|██████████| 1000/1000 [13:38<00:00,  1.21it/s]100%|██████████| 1000/1000 [13:38<00:00,  1.22it/s]
tensor(1.5434, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5462, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5443, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5565, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5480, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5520, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5481, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5451, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5506, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5457, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5525, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5480, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5436, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5506, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5468, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5503, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5519, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5477, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5463, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5496, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5542, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5450, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5447, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5511, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5439, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5420, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5478, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5425, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5433, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5414, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5451, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5456, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5415, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5469, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5415, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5387, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5461, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5420, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5444, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5426, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5455, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5460, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5389, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5413, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5433, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5479, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5456, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5463, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5439, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5452, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5485, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5481, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5457, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5413, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5433, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5460, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5439, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5406, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5488, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5457, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5442, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5430, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5443, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5419, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5486, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5484, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5426, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5472, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5454, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5462, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5463, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5462, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5418, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5494, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5463, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5428, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5429, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5470, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5413, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5377, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5395, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5407, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5446, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5419, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5405, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5387, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5407, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5469, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5422, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5397, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5449, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5443, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5432, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5451, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5428, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5426, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5484, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5440, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5443, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5421, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5453, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5470, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5432, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5435, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5400, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5437, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5418, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5467, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5408, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5429, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5425, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5440, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5387, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5431, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5492, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5450, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5457, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5409, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5434, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5442, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5443, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5411, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.5414, device='cuda:0', grad_fn=<AddBackward0>)
1000
tensor(1.5464, device='cuda:0', grad_fn=<AddBackward0>)
  0%|          | 0/50 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  2%|▏         | 1/50 [00:14<11:40, 14.29s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  4%|▍         | 2/50 [00:28<11:24, 14.27s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  6%|▌         | 3/50 [00:42<11:08, 14.23s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  8%|▊         | 4/50 [00:56<10:54, 14.24s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 10%|█         | 5/50 [01:11<10:40, 14.23s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 12%|█▏        | 6/50 [01:25<10:26, 14.23s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 14%|█▍        | 7/50 [01:39<10:11, 14.22s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 16%|█▌        | 8/50 [01:53<09:56, 14.20s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 18%|█▊        | 9/50 [02:07<09:41, 14.18s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 20%|██        | 10/50 [02:22<09:26, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 22%|██▏       | 11/50 [02:36<09:12, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 24%|██▍       | 12/50 [02:50<08:58, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 26%|██▌       | 13/50 [03:04<08:43, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 28%|██▊       | 14/50 [03:18<08:29, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 30%|███       | 15/50 [03:32<08:15, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 32%|███▏      | 16/50 [03:46<08:01, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 34%|███▍      | 17/50 [04:01<07:46, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 36%|███▌      | 18/50 [04:15<07:32, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 38%|███▊      | 19/50 [04:29<07:18, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 40%|████      | 20/50 [04:43<07:04, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 42%|████▏     | 21/50 [04:57<06:50, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 44%|████▍     | 22/50 [05:11<06:36, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 46%|████▌     | 23/50 [05:26<06:22, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 48%|████▊     | 24/50 [05:40<06:09, 14.20s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 50%|█████     | 25/50 [05:54<05:54, 14.19s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 52%|█████▏    | 26/50 [06:08<05:40, 14.18s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 54%|█████▍    | 27/50 [06:22<05:26, 14.19s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 56%|█████▌    | 28/50 [06:36<05:11, 14.18s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 58%|█████▊    | 29/50 [06:51<04:57, 14.18s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 60%|██████    | 30/50 [07:05<04:43, 14.18s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 62%|██████▏   | 31/50 [07:19<04:29, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 64%|██████▍   | 32/50 [07:33<04:15, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 66%|██████▌   | 33/50 [07:47<04:00, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 68%|██████▊   | 34/50 [08:01<03:46, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 70%|███████   | 35/50 [08:16<03:32, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 72%|███████▏  | 36/50 [08:30<03:18, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 74%|███████▍  | 37/50 [08:44<03:03, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 76%|███████▌  | 38/50 [08:58<02:49, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 78%|███████▊  | 39/50 [09:12<02:35, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 80%|████████  | 40/50 [09:26<02:21, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 82%|████████▏ | 41/50 [09:41<02:07, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 84%|████████▍ | 42/50 [09:55<01:53, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 86%|████████▌ | 43/50 [10:09<01:39, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 88%|████████▊ | 44/50 [10:23<01:24, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 90%|█████████ | 45/50 [10:37<01:10, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 92%|█████████▏| 46/50 [10:51<00:56, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 94%|█████████▍| 47/50 [11:05<00:42, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 96%|█████████▌| 48/50 [11:20<00:28, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 98%|█████████▊| 49/50 [11:34<00:14, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
100%|██████████| 50/50 [11:48<00:00, 14.15s/it]100%|██████████| 50/50 [11:48<00:00, 14.17s/it]k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing 
transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/100 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 1/100 [00:00<01:19,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  2%|▏         | 2/100 [00:01<01:18,  1.24it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  3%|▎         | 3/100 [00:02<01:19,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  4%|▍         | 4/100 [00:03<01:18,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  5%|▌         | 5/100 [00:04<01:17,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  6%|▌         | 6/100 [00:04<01:16,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  7%|▋         | 7/100 [00:05<01:15,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  8%|▊         | 8/100 [00:06<01:14,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  9%|▉         | 9/100 [00:07<01:14,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 10%|█         | 10/100 [00:08<01:13,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 11%|█         | 11/100 [00:08<01:12,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 12%|█▏        | 12/100 [00:09<01:11,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 13%|█▎        | 13/100 [00:10<01:10,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 14%|█▍        | 14/100 [00:11<01:10,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 15%|█▌        | 15/100 [00:12<01:09,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 16%|█▌        | 16/100 [00:13<01:08,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 17%|█▋        | 17/100 [00:13<01:07,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 18%|█▊        | 18/100 [00:14<01:06,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 19%|█▉        | 19/100 [00:15<01:06,  1.23it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 20%|██        | 20/100 [00:16<01:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 21%|██        | 21/100 [00:17<01:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 22%|██▏       | 22/100 [00:17<01:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 23%|██▎       | 23/100 [00:18<01:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 24%|██▍       | 24/100 [00:19<01:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 25%|██▌       | 25/100 [00:20<01:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 26%|██▌       | 26/100 [00:21<01:00,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 27%|██▋       | 27/100 [00:22<01:00,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 28%|██▊       | 28/100 [00:22<00:59,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 29%|██▉       | 29/100 [00:23<00:58,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 30%|███       | 30/100 [00:24<00:58,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 31%|███       | 31/100 [00:25<00:57,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 32%|███▏      | 32/100 [00:26<00:56,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 33%|███▎      | 33/100 [00:27<00:55,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 34%|███▍      | 34/100 [00:27<00:54,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 35%|███▌      | 35/100 [00:28<00:54,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 36%|███▌      | 36/100 [00:29<00:53,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 37%|███▋      | 37/100 [00:30<00:52,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 38%|███▊      | 38/100 [00:31<00:51,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 39%|███▉      | 39/100 [00:32<00:50,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 40%|████      | 40/100 [00:32<00:50,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 41%|████      | 41/100 [00:33<00:49,  1.19it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 42%|████▏     | 42/100 [00:34<00:48,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 43%|████▎     | 43/100 [00:35<00:47,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 44%|████▍     | 44/100 [00:36<00:46,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 45%|████▌     | 45/100 [00:37<00:45,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 46%|████▌     | 46/100 [00:37<00:45,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 47%|████▋     | 47/100 [00:38<00:44,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 48%|████▊     | 48/100 [00:39<00:43,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 49%|████▉     | 49/100 [00:40<00:42,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 50%|█████     | 50/100 [00:41<00:41,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 51%|█████     | 51/100 [00:42<00:40,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 52%|█████▏    | 52/100 [00:42<00:39,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 53%|█████▎    | 53/100 [00:43<00:39,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 54%|█████▍    | 54/100 [00:44<00:38,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 55%|█████▌    | 55/100 [00:45<00:37,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 56%|█████▌    | 56/100 [00:46<00:36,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 57%|█████▋    | 57/100 [00:47<00:35,  1.20it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 58%|█████▊    | 58/100 [00:47<00:34,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 59%|█████▉    | 59/100 [00:48<00:33,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 60%|██████    | 60/100 [00:49<00:33,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 61%|██████    | 61/100 [00:50<00:32,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 62%|██████▏   | 62/100 [00:51<00:31,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 63%|██████▎   | 63/100 [00:51<00:30,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 64%|██████▍   | 64/100 [00:52<00:29,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 65%|██████▌   | 65/100 [00:53<00:28,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 66%|██████▌   | 66/100 [00:54<00:27,  1.21it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 67%|██████▋   | 67/100 [00:55<00:27,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 68%|██████▊   | 68/100 [00:56<00:26,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 69%|██████▉   | 69/100 [00:56<00:25,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 70%|███████   | 70/100 [00:57<00:24,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 71%|███████   | 71/100 [00:58<00:23,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 72%|███████▏  | 72/100 [00:59<00:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 73%|███████▎  | 73/100 [01:00<00:22,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 74%|███████▍  | 74/100 [01:01<00:21,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 75%|███████▌  | 75/100 [01:01<00:20,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 76%|███████▌  | 76/100 [01:02<00:19,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 77%|███████▋  | 77/100 [01:03<00:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 78%|███████▊  | 78/100 [01:04<00:18,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 79%|███████▉  | 79/100 [01:05<00:17,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 80%|████████  | 80/100 [01:05<00:16,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 81%|████████  | 81/100 [01:06<00:15,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 82%|████████▏ | 82/100 [01:07<00:14,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 83%|████████▎ | 83/100 [01:08<00:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 84%|████████▍ | 84/100 [01:09<00:13,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 85%|████████▌ | 85/100 [01:10<00:12,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 86%|████████▌ | 86/100 [01:10<00:11,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 87%|████████▋ | 87/100 [01:11<00:10,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 88%|████████▊ | 88/100 [01:12<00:09,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 89%|████████▉ | 89/100 [01:13<00:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 90%|█████████ | 90/100 [01:14<00:08,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 91%|█████████ | 91/100 [01:14<00:07,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 92%|█████████▏| 92/100 [01:15<00:06,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 93%|█████████▎| 93/100 [01:16<00:05,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 94%|█████████▍| 94/100 [01:17<00:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 95%|█████████▌| 95/100 [01:18<00:04,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 96%|█████████▌| 96/100 [01:18<00:03,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 97%|█████████▋| 97/100 [01:19<00:02,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 98%|█████████▊| 98/100 [01:20<00:01,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
 99%|█████████▉| 99/100 [01:21<00:00,  1.22it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
100%|██████████| 100/100 [01:22<00:00,  1.22it/s]100%|██████████| 100/100 [01:22<00:00,  1.21it/s]
tensor(8.7177, device='cuda:0', grad_fn=<AddBackward0>)
tensor(9.6482, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.6755, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.6359, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.0924, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.8523, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.0892, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.9342, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.9930, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.3547, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.7433, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.6273, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.2348, device='cuda:0', grad_fn=<AddBackward0>)
tensor(7.0659, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.5034, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.4063, device='cuda:0', grad_fn=<AddBackward0>)
tensor(6.1021, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.8419, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.5091, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.4419, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.5480, device='cuda:0', grad_fn=<AddBackward0>)
tensor(5.4033, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.6187, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.7514, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.4523, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.5041, device='cuda:0', grad_fn=<AddBackward0>)
tensor(4.1111, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.8641, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.7208, device='cuda:0', grad_fn=<AddBackward0>)
tensor(3.3223, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.9707, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.7672, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.5239, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.8323, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.5228, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.4359, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.6619, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3976, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.5459, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.7910, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.6958, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3553, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.3351, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2191, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2375, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2571, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1829, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1900, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2474, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0686, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0573, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0171, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2749, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2193, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9998, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0206, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2390, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1710, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9529, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9617, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1827, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1015, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1954, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1958, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0992, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0987, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1813, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0427, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1051, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9954, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9238, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.1212, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9004, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9490, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9621, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0135, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9162, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9293, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8715, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0211, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9698, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8547, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0472, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9608, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8967, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8421, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0072, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0207, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9464, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8913, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0322, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9072, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9197, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.2203, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9389, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8595, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8829, device='cuda:0', grad_fn=<AddBackward0>)
tensor(2.0477, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.9666, device='cuda:0', grad_fn=<AddBackward0>)
tensor(1.8546, device='cuda:0', grad_fn=<AddBackward0>)
  0%|          | 0/50 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  2%|▏         | 1/50 [00:14<11:35, 14.20s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  4%|▍         | 2/50 [00:28<11:20, 14.18s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  6%|▌         | 3/50 [00:42<11:05, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  8%|▊         | 4/50 [00:56<10:51, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 10%|█         | 5/50 [01:10<10:37, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 12%|█▏        | 6/50 [01:24<10:23, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 14%|█▍        | 7/50 [01:39<10:08, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 16%|█▌        | 8/50 [01:53<09:54, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 18%|█▊        | 9/50 [02:07<09:40, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 20%|██        | 10/50 [02:21<09:26, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 22%|██▏       | 11/50 [02:35<09:11, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 24%|██▍       | 12/50 [02:49<08:57, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 26%|██▌       | 13/50 [03:04<08:43, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 28%|██▊       | 14/50 [03:18<08:29, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 30%|███       | 15/50 [03:32<08:15, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 32%|███▏      | 16/50 [03:46<08:01, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 34%|███▍      | 17/50 [04:00<07:46, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 36%|███▌      | 18/50 [04:14<07:32, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 38%|███▊      | 19/50 [04:28<07:18, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 40%|████      | 20/50 [04:43<07:04, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 42%|████▏     | 21/50 [04:57<06:50, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 44%|████▍     | 22/50 [05:11<06:36, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 46%|████▌     | 23/50 [05:25<06:22, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 48%|████▊     | 24/50 [05:39<06:08, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 50%|█████     | 25/50 [05:53<05:54, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 52%|█████▏    | 26/50 [06:08<05:39, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 54%|█████▍    | 27/50 [06:22<05:25, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 56%|█████▌    | 28/50 [06:36<05:11, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 58%|█████▊    | 29/50 [06:50<04:57, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 60%|██████    | 30/50 [07:04<04:42, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 62%|██████▏   | 31/50 [07:18<04:28, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 64%|██████▍   | 32/50 [07:32<04:14, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 66%|██████▌   | 33/50 [07:47<04:00, 14.13s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 68%|██████▊   | 34/50 [08:01<03:46, 14.13s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 70%|███████   | 35/50 [08:15<03:32, 14.13s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 72%|███████▏  | 36/50 [08:29<03:17, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 74%|███████▍  | 37/50 [08:43<03:03, 14.13s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 76%|███████▌  | 38/50 [08:57<02:49, 14.13s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 78%|███████▊  | 39/50 [09:11<02:35, 14.13s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 80%|████████  | 40/50 [09:25<02:21, 14.13s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 82%|████████▏ | 41/50 [09:40<02:07, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 84%|████████▍ | 42/50 [09:54<01:53, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 86%|████████▌ | 43/50 [10:08<01:38, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 88%|████████▊ | 44/50 [10:22<01:24, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 90%|█████████ | 45/50 [10:36<01:10, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 92%|█████████▏| 46/50 [10:50<00:56, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 94%|█████████▍| 47/50 [11:05<00:42, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 96%|█████████▌| 48/50 [11:19<00:28, 14.25s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
 98%|█████████▊| 49/50 [11:34<00:14, 14.33s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
100%|██████████| 50/50 [11:48<00:00, 14.40s/it]100%|██████████| 50/50 [11:48<00:00, 14.17s/it]k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing 
transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/200 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 1/200 [00:00<02:56,  1.13it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 1/200 [00:01<03:57,  1.19s/it]tensor(9.3466, device='cuda:0', grad_fn=<AddBackward0>)
tensor(8.2648, device='cuda:0', grad_fn=<AddBackward0>)
CUDA out of memory. Tried to allocate 394.00 MiB (GPU 0; 9.77 GiB total capacity; 6.88 GiB already allocated; 80.75 MiB free; 7.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing 
transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/350 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 1/350 [00:00<04:55,  1.18it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 1/350 [00:01<06:37,  1.14s/it]tensor(8.8716, device='cuda:0', grad_fn=<AddBackward0>)
CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 6.09 GiB already allocated; 788.75 MiB free; 6.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj

Initializing transformer.h.25.attn.q_proj
Adding adapter to transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 66.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/52 [00:00<?, ?it/s]  0%|          | 0/52 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/104 [00:00<?, ?it/s]  0%|          | 0/104 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/182 [00:00<?, ?it/s]  0%|          | 0/182 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/260 [00:00<?, ?it/s]  0%|          | 0/260 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/40 [00:00<?, ?it/s]  0%|          | 0/40 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/70 [00:00<?, ?it/s]  0%|          | 0/70 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/12 [00:00<?, ?it/s]  0%|          | 0/12 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/24 [00:00<?, ?it/s]  0%|          | 0/24 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/42 [00:00<?, ?it/s]  0%|          | 0/42 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/60 [00:00<?, ?it/s]  0%|          | 0/60 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
test_size=-112 should be either positive and smaller than the number of samples 88 or a float in the (0, 1) range
test_size=-112 should be either positive and smaller than the number of samples 88 or a float in the (0, 1) range
test_size=-112 should be either positive and smaller than the number of samples 88 or a float in the (0, 1) range
test_size=-112 should be either positive and smaller than the number of samples 88 or a float in the (0, 1) range
test_size=-12 should be either positive and smaller than the number of samples 88 or a float in the (0, 1) range
test_size=-12 should be either positive and smaller than the number of samples 88 or a float in the (0, 1) range
test_size=-12 should be either positive and smaller than the number of samples 88 or a float in the (0, 1) range
test_size=-12 should be either positive and smaller than the number of samples 88 or a float in the (0, 1) range
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to 
transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/52 [00:00<?, ?it/s]  0%|          | 0/52 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/104 [00:00<?, ?it/s]  0%|          | 0/104 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/182 [00:00<?, ?it/s]  0%|          | 0/182 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/260 [00:00<?, ?it/s]  0%|          | 0/260 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/40 [00:00<?, ?it/s]  0%|          | 0/40 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/70 [00:00<?, ?it/s]  0%|          | 0/70 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/12 [00:00<?, ?it/s]  0%|          | 0/12 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/24 [00:00<?, ?it/s]  0%|          | 0/24 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/42 [00:00<?, ?it/s]  0%|          | 0/42 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/60 [00:00<?, ?it/s]  0%|          | 0/60 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 0/200 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/400 [00:00<?, ?it/s]  0%|          | 0/400 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/700 [00:00<?, ?it/s]  0%|          | 0/700 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/1000 [00:00<?, ?it/s]  0%|          | 0/1000 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 0/200 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/350 [00:00<?, ?it/s]  0%|          | 0/350 [00:00<?, ?it/s]CUDA out of memory. Tried to allocate 788.00 MiB (GPU 0; 9.77 GiB total capacity; 5.79 GiB already allocated; 2.75 MiB free; 6.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
k_proj Linear(in_features=4096, out_features=4096, bias=False)
v_proj Linear(in_features=4096, out_features=4096, bias=False)
q_proj Linear(in_features=4096, out_features=4096, bias=False)
out_proj Linear(in_features=4096, out_features=4096, bias=False)
fc_in Linear(in_features=4096, out_features=16384, bias=True)
fc_out Linear(in_features=16384, out_features=4096, bias=True)
lm_head Linear(in_features=4096, out_features=50400, bias=True)
Adding adapter to transformer.wte
Initializing transformer.wte
Adding adapter to transformer.h.0.attn.k_proj
Initializing transformer.h.0.attn.k_proj
Adding adapter to transformer.h.0.attn.v_proj
Initializing transformer.h.0.attn.v_proj
Adding adapter to transformer.h.0.attn.q_proj
Initializing transformer.h.0.attn.q_proj
Adding adapter to transformer.h.0.attn.out_proj
Initializing transformer.h.0.attn.out_proj
Adding adapter to transformer.h.0.mlp.fc_in
Initializing transformer.h.0.mlp.fc_in
Adding adapter to transformer.h.0.mlp.fc_out
Initializing transformer.h.0.mlp.fc_out
Adding adapter to transformer.h.1.attn.k_proj
Initializing transformer.h.1.attn.k_proj
Adding adapter to transformer.h.1.attn.v_proj
Initializing transformer.h.1.attn.v_proj
Adding adapter to transformer.h.1.attn.q_proj
Initializing transformer.h.1.attn.q_proj
Adding adapter to transformer.h.1.attn.out_proj
Initializing transformer.h.1.attn.out_proj
Adding adapter to transformer.h.1.mlp.fc_in
Initializing transformer.h.1.mlp.fc_in
Adding adapter to transformer.h.1.mlp.fc_out
Initializing transformer.h.1.mlp.fc_out
Adding adapter to transformer.h.2.attn.k_proj
Initializing transformer.h.2.attn.k_proj
Adding adapter to transformer.h.2.attn.v_proj
Initializing transformer.h.2.attn.v_proj
Adding adapter to transformer.h.2.attn.q_proj
Initializing transformer.h.2.attn.q_proj
Adding adapter to transformer.h.2.attn.out_proj
Initializing transformer.h.2.attn.out_proj
Adding adapter to transformer.h.2.mlp.fc_in
Initializing transformer.h.2.mlp.fc_in
Adding adapter to transformer.h.2.mlp.fc_out
Initializing transformer.h.2.mlp.fc_out
Adding adapter to transformer.h.3.attn.k_proj
Initializing transformer.h.3.attn.k_proj
Adding adapter to transformer.h.3.attn.v_proj
Initializing transformer.h.3.attn.v_proj
Adding adapter to transformer.h.3.attn.q_proj
Initializing transformer.h.3.attn.q_proj
Adding adapter to transformer.h.3.attn.out_proj
Initializing transformer.h.3.attn.out_proj
Adding adapter to transformer.h.3.mlp.fc_in
Initializing transformer.h.3.mlp.fc_in
Adding adapter to transformer.h.3.mlp.fc_out
Initializing transformer.h.3.mlp.fc_out
Adding adapter to transformer.h.4.attn.k_proj
Initializing transformer.h.4.attn.k_proj
Adding adapter to transformer.h.4.attn.v_proj
Initializing transformer.h.4.attn.v_proj
Adding adapter to transformer.h.4.attn.q_proj
Initializing transformer.h.4.attn.q_proj
Adding adapter to transformer.h.4.attn.out_proj
Initializing transformer.h.4.attn.out_proj
Adding adapter to transformer.h.4.mlp.fc_in
Initializing transformer.h.4.mlp.fc_in
Adding adapter to transformer.h.4.mlp.fc_out
Initializing transformer.h.4.mlp.fc_out
Adding adapter to transformer.h.5.attn.k_proj
Initializing transformer.h.5.attn.k_proj
Adding adapter to transformer.h.5.attn.v_proj
Initializing transformer.h.5.attn.v_proj
Adding adapter to transformer.h.5.attn.q_proj
Initializing transformer.h.5.attn.q_proj
Adding adapter to transformer.h.5.attn.out_proj
Initializing transformer.h.5.attn.out_proj
Adding adapter to transformer.h.5.mlp.fc_in
Initializing transformer.h.5.mlp.fc_in
Adding adapter to transformer.h.5.mlp.fc_out
Initializing transformer.h.5.mlp.fc_out
Adding adapter to transformer.h.6.attn.k_proj
Initializing transformer.h.6.attn.k_proj
Adding adapter to transformer.h.6.attn.v_proj
Initializing transformer.h.6.attn.v_proj
Adding adapter to transformer.h.6.attn.q_proj
Initializing transformer.h.6.attn.q_proj
Adding adapter to transformer.h.6.attn.out_proj
Initializing transformer.h.6.attn.out_proj
Adding adapter to transformer.h.6.mlp.fc_in
Initializing transformer.h.6.mlp.fc_in
Adding adapter to transformer.h.6.mlp.fc_out
Initializing transformer.h.6.mlp.fc_out
Adding adapter to transformer.h.7.attn.k_proj
Initializing transformer.h.7.attn.k_proj
Adding adapter to transformer.h.7.attn.v_proj
Initializing transformer.h.7.attn.v_proj
Adding adapter to transformer.h.7.attn.q_proj
Initializing transformer.h.7.attn.q_proj
Adding adapter to transformer.h.7.attn.out_proj
Initializing transformer.h.7.attn.out_proj
Adding adapter to transformer.h.7.mlp.fc_in
Initializing transformer.h.7.mlp.fc_in
Adding adapter to transformer.h.7.mlp.fc_out
Initializing transformer.h.7.mlp.fc_out
Adding adapter to transformer.h.8.attn.k_proj
Initializing transformer.h.8.attn.k_proj
Adding adapter to transformer.h.8.attn.v_proj
Initializing transformer.h.8.attn.v_proj
Adding adapter to transformer.h.8.attn.q_proj
Initializing transformer.h.8.attn.q_proj
Adding adapter to transformer.h.8.attn.out_proj
Initializing transformer.h.8.attn.out_proj
Adding adapter to transformer.h.8.mlp.fc_in
Initializing transformer.h.8.mlp.fc_in
Adding adapter to transformer.h.8.mlp.fc_out
Initializing transformer.h.8.mlp.fc_out
Adding adapter to transformer.h.9.attn.k_proj
Initializing transformer.h.9.attn.k_proj
Adding adapter to transformer.h.9.attn.v_proj
Initializing transformer.h.9.attn.v_proj
Adding adapter to transformer.h.9.attn.q_proj
Initializing transformer.h.9.attn.q_proj
Adding adapter to transformer.h.9.attn.out_proj
Initializing transformer.h.9.attn.out_proj
Adding adapter to transformer.h.9.mlp.fc_in
Initializing transformer.h.9.mlp.fc_in
Adding adapter to transformer.h.9.mlp.fc_out
Initializing transformer.h.9.mlp.fc_out
Adding adapter to transformer.h.10.attn.k_proj
Initializing transformer.h.10.attn.k_proj
Adding adapter to transformer.h.10.attn.v_proj
Initializing transformer.h.10.attn.v_proj
Adding adapter to transformer.h.10.attn.q_proj
Initializing transformer.h.10.attn.q_proj
Adding adapter to transformer.h.10.attn.out_proj
Initializing transformer.h.10.attn.out_proj
Adding adapter to transformer.h.10.mlp.fc_in
Initializing transformer.h.10.mlp.fc_in
Adding adapter to transformer.h.10.mlp.fc_out
Initializing transformer.h.10.mlp.fc_out
Adding adapter to transformer.h.11.attn.k_proj
Initializing transformer.h.11.attn.k_proj
Adding adapter to transformer.h.11.attn.v_proj
Initializing transformer.h.11.attn.v_proj
Adding adapter to transformer.h.11.attn.q_proj
Initializing transformer.h.11.attn.q_proj
Adding adapter to transformer.h.11.attn.out_proj
Initializing transformer.h.11.attn.out_proj
Adding adapter to transformer.h.11.mlp.fc_in
Initializing transformer.h.11.mlp.fc_in
Adding adapter to transformer.h.11.mlp.fc_out
Initializing transformer.h.11.mlp.fc_out
Adding adapter to transformer.h.12.attn.k_proj
Initializing transformer.h.12.attn.k_proj
Adding adapter to transformer.h.12.attn.v_proj
Initializing transformer.h.12.attn.v_proj
Adding adapter to transformer.h.12.attn.q_proj
Initializing transformer.h.12.attn.q_proj
Adding adapter to transformer.h.12.attn.out_proj
Initializing transformer.h.12.attn.out_proj
Adding adapter to transformer.h.12.mlp.fc_in
Initializing transformer.h.12.mlp.fc_in
Adding adapter to transformer.h.12.mlp.fc_out
Initializing transformer.h.12.mlp.fc_out
Adding adapter to transformer.h.13.attn.k_proj
Initializing transformer.h.13.attn.k_proj
Adding adapter to transformer.h.13.attn.v_proj
Initializing transformer.h.13.attn.v_proj
Adding adapter to transformer.h.13.attn.q_proj
Initializing transformer.h.13.attn.q_proj
Adding adapter to transformer.h.13.attn.out_proj
Initializing transformer.h.13.attn.out_proj
Adding adapter to transformer.h.13.mlp.fc_in
Initializing transformer.h.13.mlp.fc_in
Adding adapter to transformer.h.13.mlp.fc_out
Initializing transformer.h.13.mlp.fc_out
Adding adapter to transformer.h.14.attn.k_proj
Initializing transformer.h.14.attn.k_proj
Adding adapter to transformer.h.14.attn.v_proj
Initializing transformer.h.14.attn.v_proj
Adding adapter to transformer.h.14.attn.q_proj
Initializing transformer.h.14.attn.q_proj
Adding adapter to transformer.h.14.attn.out_proj
Initializing transformer.h.14.attn.out_proj
Adding adapter to transformer.h.14.mlp.fc_in
Initializing transformer.h.14.mlp.fc_in
Adding adapter to transformer.h.14.mlp.fc_out
Initializing transformer.h.14.mlp.fc_out
Adding adapter to transformer.h.15.attn.k_proj
Initializing transformer.h.15.attn.k_proj
Adding adapter to transformer.h.15.attn.v_proj
Initializing transformer.h.15.attn.v_proj
Adding adapter to transformer.h.15.attn.q_proj
Initializing transformer.h.15.attn.q_proj
Adding adapter to transformer.h.15.attn.out_proj
Initializing transformer.h.15.attn.out_proj
Adding adapter to transformer.h.15.mlp.fc_in
Initializing transformer.h.15.mlp.fc_in
Adding adapter to transformer.h.15.mlp.fc_out
Initializing transformer.h.15.mlp.fc_out
Adding adapter to transformer.h.16.attn.k_proj
Initializing transformer.h.16.attn.k_proj
Adding adapter to transformer.h.16.attn.v_proj
Initializing transformer.h.16.attn.v_proj
Adding adapter to transformer.h.16.attn.q_proj
Initializing transformer.h.16.attn.q_proj
Adding adapter to transformer.h.16.attn.out_proj
Initializing transformer.h.16.attn.out_proj
Adding adapter to transformer.h.16.mlp.fc_in
Initializing transformer.h.16.mlp.fc_in
Adding adapter to transformer.h.16.mlp.fc_out
Initializing transformer.h.16.mlp.fc_out
Adding adapter to transformer.h.17.attn.k_proj
Initializing transformer.h.17.attn.k_proj
Adding adapter to transformer.h.17.attn.v_proj
Initializing transformer.h.17.attn.v_proj
Adding adapter to transformer.h.17.attn.q_proj
Initializing transformer.h.17.attn.q_proj
Adding adapter to transformer.h.17.attn.out_proj
Initializing transformer.h.17.attn.out_proj
Adding adapter to transformer.h.17.mlp.fc_in
Initializing transformer.h.17.mlp.fc_in
Adding adapter to transformer.h.17.mlp.fc_out
Initializing transformer.h.17.mlp.fc_out
Adding adapter to transformer.h.18.attn.k_proj
Initializing transformer.h.18.attn.k_proj
Adding adapter to transformer.h.18.attn.v_proj
Initializing transformer.h.18.attn.v_proj
Adding adapter to transformer.h.18.attn.q_proj
Initializing transformer.h.18.attn.q_proj
Adding adapter to transformer.h.18.attn.out_proj
Initializing transformer.h.18.attn.out_proj
Adding adapter to transformer.h.18.mlp.fc_in
Initializing transformer.h.18.mlp.fc_in
Adding adapter to transformer.h.18.mlp.fc_out
Initializing transformer.h.18.mlp.fc_out
Adding adapter to transformer.h.19.attn.k_proj
Initializing transformer.h.19.attn.k_proj
Adding adapter to transformer.h.19.attn.v_proj
Initializing transformer.h.19.attn.v_proj
Adding adapter to transformer.h.19.attn.q_proj
Initializing transformer.h.19.attn.q_proj
Adding adapter to transformer.h.19.attn.out_proj
Initializing transformer.h.19.attn.out_proj
Adding adapter to transformer.h.19.mlp.fc_in
Initializing transformer.h.19.mlp.fc_in
Adding adapter to transformer.h.19.mlp.fc_out
Initializing transformer.h.19.mlp.fc_out
Adding adapter to transformer.h.20.attn.k_proj
Initializing transformer.h.20.attn.k_proj
Adding adapter to transformer.h.20.attn.v_proj
Initializing transformer.h.20.attn.v_proj
Adding adapter to transformer.h.20.attn.q_proj
Initializing transformer.h.20.attn.q_proj
Adding adapter to transformer.h.20.attn.out_proj
Initializing transformer.h.20.attn.out_proj
Adding adapter to transformer.h.20.mlp.fc_in
Initializing transformer.h.20.mlp.fc_in
Adding adapter to transformer.h.20.mlp.fc_out
Initializing transformer.h.20.mlp.fc_out
Adding adapter to transformer.h.21.attn.k_proj
Initializing transformer.h.21.attn.k_proj
Adding adapter to transformer.h.21.attn.v_proj
Initializing transformer.h.21.attn.v_proj
Adding adapter to transformer.h.21.attn.q_proj
Initializing transformer.h.21.attn.q_proj
Adding adapter to transformer.h.21.attn.out_proj
Initializing transformer.h.21.attn.out_proj
Adding adapter to transformer.h.21.mlp.fc_in
Initializing transformer.h.21.mlp.fc_in
Adding adapter to transformer.h.21.mlp.fc_out
Initializing transformer.h.21.mlp.fc_out
Adding adapter to transformer.h.22.attn.k_proj
Initializing transformer.h.22.attn.k_proj
Adding adapter to transformer.h.22.attn.v_proj
Initializing transformer.h.22.attn.v_proj
Adding adapter to transformer.h.22.attn.q_proj
Initializing transformer.h.22.attn.q_proj
Adding adapter to transformer.h.22.attn.out_proj
Initializing transformer.h.22.attn.out_proj
Adding adapter to transformer.h.22.mlp.fc_in
Initializing transformer.h.22.mlp.fc_in
Adding adapter to transformer.h.22.mlp.fc_out
Initializing transformer.h.22.mlp.fc_out
Adding adapter to transformer.h.23.attn.k_proj
Initializing transformer.h.23.attn.k_proj
Adding adapter to transformer.h.23.attn.v_proj
Initializing transformer.h.23.attn.v_proj
Adding adapter to transformer.h.23.attn.q_proj
Initializing transformer.h.23.attn.q_proj
Adding adapter to transformer.h.23.attn.out_proj
Initializing transformer.h.23.attn.out_proj
Adding adapter to transformer.h.23.mlp.fc_in
Initializing transformer.h.23.mlp.fc_in
Adding adapter to transformer.h.23.mlp.fc_out
Initializing transformer.h.23.mlp.fc_out
Adding adapter to transformer.h.24.attn.k_proj
Initializing transformer.h.24.attn.k_proj
Adding adapter to transformer.h.24.attn.v_proj
Initializing transformer.h.24.attn.v_proj
Adding adapter to transformer.h.24.attn.q_proj
Initializing transformer.h.24.attn.q_proj
Adding adapter to transformer.h.24.attn.out_proj
Initializing transformer.h.24.attn.out_proj
Adding adapter to transformer.h.24.mlp.fc_in
Initializing transformer.h.24.mlp.fc_in
Adding adapter to transformer.h.24.mlp.fc_out
Initializing transformer.h.24.mlp.fc_out
Adding adapter to transformer.h.25.attn.k_proj
Initializing transformer.h.25.attn.k_proj
Adding adapter to transformer.h.25.attn.v_proj
Initializing transformer.h.25.attn.v_proj
Adding adapter to transformer.h.25.attn.q_proj
Initializing transformer.h.25.attn.q_proj
Adding adapter to 
transformer.h.25.attn.out_proj
Initializing transformer.h.25.attn.out_proj
Adding adapter to transformer.h.25.mlp.fc_in
Initializing transformer.h.25.mlp.fc_in
Adding adapter to transformer.h.25.mlp.fc_out
Initializing transformer.h.25.mlp.fc_out
Adding adapter to transformer.h.26.attn.k_proj
Initializing transformer.h.26.attn.k_proj
Adding adapter to transformer.h.26.attn.v_proj
Initializing transformer.h.26.attn.v_proj
Adding adapter to transformer.h.26.attn.q_proj
Initializing transformer.h.26.attn.q_proj
Adding adapter to transformer.h.26.attn.out_proj
Initializing transformer.h.26.attn.out_proj
Adding adapter to transformer.h.26.mlp.fc_in
Initializing transformer.h.26.mlp.fc_in
Adding adapter to transformer.h.26.mlp.fc_out
Initializing transformer.h.26.mlp.fc_out
Adding adapter to transformer.h.27.attn.k_proj
Initializing transformer.h.27.attn.k_proj
Adding adapter to transformer.h.27.attn.v_proj
Initializing transformer.h.27.attn.v_proj
Adding adapter to transformer.h.27.attn.q_proj
Initializing transformer.h.27.attn.q_proj
Adding adapter to transformer.h.27.attn.out_proj
Initializing transformer.h.27.attn.out_proj
Adding adapter to transformer.h.27.mlp.fc_in
Initializing transformer.h.27.mlp.fc_in
Adding adapter to transformer.h.27.mlp.fc_out
Initializing transformer.h.27.mlp.fc_out
Adding adapter to lm_head
Initializing lm_head
cuda:0
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:00<?, ?it/s]